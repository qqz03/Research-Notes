<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.15.6/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.15.6/dist/browser/index.js"></script><script>((getMarkmap) => {
          window.WebFontConfig = {
            custom: {
              families: [
                "KaTeX_AMS",
                "KaTeX_Caligraphic:n4,n7",
                "KaTeX_Fraktur:n4,n7",
                "KaTeX_Main:n4,n7,i4,i7",
                "KaTeX_Math:i4,i7",
                "KaTeX_Script",
                "KaTeX_SansSerif:n4,n7,i4",
                "KaTeX_Size1",
                "KaTeX_Size2",
                "KaTeX_Size3",
                "KaTeX_Size4",
                "KaTeX_Typewriter"
              ]
            },
            active: () => {
              getMarkmap().refreshHook.call();
            }
          };
        })(() => window.markmap)</script><script src="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.js" defer></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.15.6/dist/index.js"></script><script>(r => {
                setTimeout(r);
              })(() => {
  const {
    markmap,
    mm
  } = window;
  const {
    el
  } = markmap.Toolbar.create(mm);
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
                const markmap = getMarkmap();
                window.mm = markmap.Markmap.create(
                  "svg#mindmap",
                  (getOptions || markmap.deriveOptions)(jsonOptions),
                  root2
                );
              })(() => window.markmap,null,{"type":"root","depth":0,"content":"","children":[{"type":"paragraph","depth":1,"payload":{"lines":[0,3]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0em;\"></span><span class=\"mord\"><span class=\"mord\"></span></span></span></span></span><br>\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mrow></mrow></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0em;\"></span><span class=\"mord text\" style=\"color:green;\"></span></span></span></span><br>\n<img src=\".png\" alt=\"\">","children":[]},{"type":"bullet_list","depth":1,"payload":{"lines":[4,782]},"content":"","children":[{"type":"list_item","depth":2,"payload":{"lines":[4,5]},"content":"<strong>深度学习</strong>","children":[{"type":"list_item","depth":3,"payload":{"lines":[5,6]},"content":"<strong>网路结构</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[6,7]},"content":"<strong><em>MLP</em> （全连接）</strong>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[7,8]},"content":"<strong><em>CNN</em></strong>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[8,9]},"content":"<strong><em>RNN</em></strong>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[9,10]},"content":"<strong><em>DBN (Deep Belief Network) <mark>TODO</mark></em></strong>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[10,11]},"content":"<strong><em>GAN</em></strong>","children":[]}]},{"type":"list_item","depth":3,"payload":{"lines":[11,12]},"content":"<strong>激活函数</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[12,13]},"content":"<strong><em>Sigmoid</em></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[13,14]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">S</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn mathvariant=\"bold\">1</mn><mrow><mn mathvariant=\"bold\">1</mn><mo mathvariant=\"bold-italic\">+</mo><msup><mi mathvariant=\"bold-italic\">e</mi><mrow><mo mathvariant=\"bold-italic\">−</mo><mi mathvariant=\"bold-italic\">x</mi></mrow></msup></mrow></mfrac></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{S(x)=\\frac{1}{1+e^{-x}}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2834em;vertical-align:-0.4383em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.05382em;\">S</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">1</span><span class=\"mbin mathbf mtight\">+</span><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7384em;\"><span style=\"top:-2.786em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">−</span><span class=\"mord boldsymbol mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4383em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[14,15]},"content":"<strong>易于求导</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[15,16]},"content":"<strong>但反传时易“梯度消失”</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[16,17]},"content":"<strong><em>tanh</em></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[17,18]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi>tanh</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><msup><mi mathvariant=\"bold-italic\">e</mi><mi mathvariant=\"bold-italic\">x</mi></msup><mo mathvariant=\"bold-italic\">−</mo><msup><mi mathvariant=\"bold-italic\">e</mi><mrow><mo mathvariant=\"bold-italic\">−</mo><mi mathvariant=\"bold-italic\">x</mi></mrow></msup></mrow><mrow><msup><mi mathvariant=\"bold-italic\">e</mi><mi mathvariant=\"bold-italic\">x</mi></msup><mo mathvariant=\"bold-italic\">+</mo><msup><mi mathvariant=\"bold-italic\">e</mi><mrow><mo mathvariant=\"bold-italic\">−</mo><mi mathvariant=\"bold-italic\">x</mi></mrow></msup></mrow></mfrac></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{\\tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.46em;vertical-align:-0.4383em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mop\"><span class=\"mathbf\">t</span><span class=\"mathbf\">a</span><span class=\"mathbf\">n</span><span class=\"mathbf\">h</span></span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0217em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6035em;\"><span style=\"top:-2.786em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">x</span></span></span></span></span></span></span></span></span><span class=\"mbin mathbf mtight\">+</span><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7384em;\"><span style=\"top:-2.786em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">−</span><span class=\"mord boldsymbol mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4033em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7485em;\"><span style=\"top:-2.931em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">x</span></span></span></span></span></span></span></span></span><span class=\"mbin mathbf mtight\">−</span><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8834em;\"><span style=\"top:-2.931em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">−</span><span class=\"mord boldsymbol mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4383em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[18,19]},"content":"<strong>均值为0，更快收敛</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[19,20]},"content":"<strong>但反传时易“梯度消失”</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[20,21]},"content":"<strong><em>ReLU (Rectified Linear Unit)</em></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[21,22]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">R</mi><mi mathvariant=\"bold-italic\">e</mi><mi mathvariant=\"bold-italic\">L</mi><mi mathvariant=\"bold-italic\">U</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi mathvariant=\"bold-italic\">m</mi><mi mathvariant=\"bold-italic\">a</mi><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">(</mo><mn mathvariant=\"bold\">0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{ReLU(x) = max(0, x)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11424em;\">ReLU</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord boldsymbol\">max</span><span class=\"mopen mathbf\">(</span><span class=\"mord mathbf\">0</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[22,23]},"content":"<strong><em>Leakly ReLU</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[23,24]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mrow><mo fence=\"true\">{</mo><mtable rowspacing=\"0.36em\" columnalign=\"left left\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mi mathvariant=\"bold-italic\">x</mi></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mspace width=\"1em\"/><mi mathvariant=\"bold-italic\">x</mi><mo>&gt;</mo><mn mathvariant=\"bold\">0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi mathvariant=\"bold-italic\">λ</mi><mi mathvariant=\"bold-italic\">x</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mspace width=\"1em\"/><mi mathvariant=\"bold-italic\">x</mi><mo>⩽</mo><mn mathvariant=\"bold\">0</mn></mrow></mstyle></mtd></mtr></mtable></mrow><mo separator=\"true\">;</mo><mi mathvariant=\"bold-italic\">λ</mi><mo>∈</mo><mo stretchy=\"false\">(</mo><mn mathvariant=\"bold\">0</mn><mo separator=\"true\">,</mo><mn mathvariant=\"bold\">1</mn><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f(x) = \\begin{cases}x &amp; \\quad x&gt;0 \\\\\\lambda x &amp; \\quad x \\leqslant 0 \\end{cases}; \\lambda\\in(0,1)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:3em;vertical-align:-1.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">{</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.69em;\"><span style=\"top:-3.69em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-2.25em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span><span class=\"mord mathnormal\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.19em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:1em;\"></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.69em;\"><span style=\"top:-3.69em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">0</span></span></span><span style=\"top:-2.25em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel amsrm\">⩽</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.19em;\"><span></span></span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mpunct mathbf\">;</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\">λ</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mopen mathbf\">(</span><span class=\"mord mathbf\">0</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathbf\">1</span><span class=\"mclose mathbf\">)</span></span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[24,25]},"content":"<strong><em>RReLU (Randomized leaky ReLU)</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[25,26]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mrow><mo fence=\"true\">{</mo><mtable rowspacing=\"0.36em\" columnalign=\"left left\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mi mathvariant=\"bold-italic\">x</mi></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mspace width=\"1em\"/><mi mathvariant=\"bold-italic\">x</mi><mo>&gt;</mo><mn mathvariant=\"bold\">0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi mathvariant=\"bold-italic\">λ</mi><mi mathvariant=\"bold-italic\">x</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mspace width=\"1em\"/><mi mathvariant=\"bold-italic\">x</mi><mo>⩽</mo><mn mathvariant=\"bold\">0</mn></mrow></mstyle></mtd></mtr></mtable></mrow><mo separator=\"true\">;</mo><mi mathvariant=\"bold-italic\">λ</mi><mo>∼</mo><mi mathvariant=\"normal\">U</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">l</mi><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">u</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">l</mi><mo>&lt;</mo><mi mathvariant=\"bold-italic\">u</mi><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">l</mi><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">u</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn mathvariant=\"bold\">0</mn><mo separator=\"true\">,</mo><mn mathvariant=\"bold\">1</mn><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f(x) = \\begin{cases}x &amp; \\quad x&gt;0 \\\\\\lambda x &amp; \\quad x \\leqslant 0 \\end{cases}; \\lambda\\sim\\mathrm{U}(l,u), l&lt;u, l,u\\in[0,1)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:3em;vertical-align:-1.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">{</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.69em;\"><span style=\"top:-3.69em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-2.25em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span><span class=\"mord mathnormal\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.19em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:1em;\"></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.69em;\"><span style=\"top:-3.69em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">0</span></span></span><span style=\"top:-2.25em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel amsrm\">⩽</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.19em;\"><span></span></span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mpunct mathbf\">;</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\">λ</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">∼</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathrm\">U</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\">u</span><span class=\"mclose mathbf\">)</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord boldsymbol\">u</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\">u</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mopen mathbf\">[</span><span class=\"mord mathbf\">0</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathbf\">1</span><span class=\"mclose mathbf\">)</span></span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[26,27]},"content":"<strong><em>Noisy ReLU</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[27,28]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn mathvariant=\"bold\">0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">x</mi><mo mathvariant=\"bold-italic\">+</mo><mi mathvariant=\"bold-italic\">Y</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">;</mo><mi mathvariant=\"bold-italic\">Y</mi><mo>∼</mo><mi mathvariant=\"normal\">N</mi><mo stretchy=\"false\">(</mo><mn mathvariant=\"bold\">0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">σ</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f(x) =\\max(0,x+Y); Y\\sim\\mathrm{N}(0,\\sigma(x))}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mop\"><span class=\"mathbf\">m</span><span class=\"mathbf\">a</span><span class=\"mathbf\">x</span></span><span class=\"mopen mathbf\">(</span><span class=\"mord mathbf\">0</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.25555em;\">Y</span><span class=\"mclose mathbf\">)</span><span class=\"mpunct mathbf\">;</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.25555em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">∼</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathrm\">N</span><span class=\"mopen mathbf\">(</span><span class=\"mord mathbf\">0</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">σ</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">))</span></span></span></span></span></span>","children":[]}]}]},{"type":"list_item","depth":4,"payload":{"lines":[28,29]},"content":"<img src=\"activation_function.png\" alt=\"\" title=\"激活函数\">","children":[]}]},{"type":"list_item","depth":3,"payload":{"lines":[29,30]},"content":"<strong>损失函数</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[30,31]},"content":"<strong><em>CrossEntropy</em></strong>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[31,32]},"content":"<strong><em>MSE (Mean-Square Error)</em>损失函数</strong>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[32,33]},"content":"<strong><em>log</em> 损失函数</strong>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[33,34]},"content":"<strong>指数损失函数</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[34,35]},"content":"<strong><em>Adaboost</em></strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[35,36]},"content":"<strong><em>Hinge</em> 损失函数</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[36,37]},"content":"<img src=\"loss_function.png\" alt=\"\" title=\"损失函数\">","children":[]}]}]},{"type":"list_item","depth":3,"payload":{"lines":[37,38]},"content":"<strong>模型复杂度</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[38,39]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Why should I trust you? Explaining the predictions of any classifier</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Why should I trust you? Explaining the predictions of any classifier}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Why should I trust you? Explaining the predictions of any classifier</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":3,"payload":{"lines":[39,40]},"content":"<strong>可解释性定义</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[40,41]},"content":"<strong>2017, Kim, <em>&quot;Interpretation is the process of giving explanations to Human&quot;</em></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[41,42]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable machine learning: the fuss，the concrete and the questions</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable machine learning: the fuss，the concrete and the questions}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable machine learning: the fuss</span><span class=\"mord cjk_fallback\" style=\"color:green;\">，</span><span class=\"mord\" style=\"color:green;\">the concrete and the questions</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[42,43]},"content":"<strong>Doshi-Velez, <em>&quot;Interpretability is the ability to explain or to present in understandable terms to a human&quot;</em></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[43,44]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Towards a rigorous science of interpretable machine learning</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Towards a rigorous science of interpretable machine learning}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Towards a rigorous science of interpretable machine learning</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[44,45]},"content":"<strong>Miller</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[45,46]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Explanation in artificial intelligence: insights from the social sciences</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Explanation in artificial intelligence: insights from the social sciences}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Explanation in artificial intelligence: insights from the social sciences</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[46,47]},"content":"<strong>Molnar</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[47,48]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A Guide for Making Black Box Models Explainable</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A Guide for Making Black Box Models Explainable}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A Guide for Making Black Box Models Explainable</span></span></span></span></span>","children":[]}]}]},{"type":"list_item","depth":3,"payload":{"lines":[48,49]},"content":"<strong>可解释性方法</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[49,50]},"content":"<strong>事前(ante-hoc)可解释性</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[50,51]},"content":"通过<strong>训练结构简单、可解释性好的模型或将可解释性结合到具体的模型结构中的自解释模型使模型本身具备可解释能力</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[51,52]},"content":"<strong>模型本身内置可解释性</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[52,53]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Towards robust interpretability with self-explaining neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Towards robust interpretability with self-explaining neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Towards robust interpretability with self-explaining neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[53,54]},"content":"<strong>自解释模型 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[54,55]},"content":"<strong>模型整体的可模拟性(simulatability)</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[55,56]},"content":"<strong>模型透明</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[56,57]},"content":"<strong>整体上完全理解</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[57,58]},"content":"将<strong>输入数据连同模型的参数</strong>一起，在<strong>合理的时间</strong>步骤<strong>内</strong>完成产生<strong>预测所需的每一个计算</strong>","children":[]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[58,59]},"content":"<strong>模型单个组件的可分解性(decomposability)</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[59,60]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Intelligible models for classification and regression</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Intelligible models for classification and regression}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Intelligible models for classification and regression</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[60,61]},"content":"<strong>模型的每个部分</strong>，包括<strong>模型结构、模型参数</strong>，模型的<strong>每一个输入以及每一维特征</strong>都允许<strong>直观的解释</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[61,62]},"content":"<strong>内置可解释性与模型准确性的矛盾</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[62,63]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A survey of methods for explaining black box models</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A survey of methods for explaining black box models}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A survey of methods for explaining black box models</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[63,64]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Simplifying decision trees: A survey</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Simplifying decision trees: A survey}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Simplifying decision trees: A survey</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[64,65]},"content":"对于决策树模型和基于规则的模型，<strong>如果树深度太深或者模型的规则太复杂</strong>，人类<strong>也未必能理解</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[65,66]},"content":"<strong>广义加性模型(GAM) <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[66,67]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Intelligible models for classification and regression</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Intelligible models for classification and regression}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Intelligible models for classification and regression</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[67,68]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Statistical Models in S</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Statistical Models in S}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Statistical Models in S</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[68,69]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Generalized additive models: An introduction with R</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Generalized additive models: An introduction with R}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Generalized additive models: An introduction with R</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[69,70]},"content":"既能<strong>提高简单线性模型的准确率</strong>，又能<strong>保留线性模型良好的内置可解释性</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[70,71]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">g</mi><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">y</mi><mo fence=\"true\">)</mo></mrow><mo>=</mo><msub><mi mathvariant=\"bold-italic\">f</mi><mn mathvariant=\"bold\">1</mn></msub><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mn mathvariant=\"bold\">1</mn></msub><mo fence=\"true\">)</mo></mrow><mo mathvariant=\"bold-italic\">+</mo><msub><mi mathvariant=\"bold-italic\">f</mi><mn mathvariant=\"bold\">2</mn></msub><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mn mathvariant=\"bold\">2</mn></msub><mo fence=\"true\">)</mo></mrow><mo mathvariant=\"bold-italic\">+</mo><mo separator=\"true\">⋅</mo><mo separator=\"true\">⋅</mo><mo separator=\"true\">⋅</mo><mo mathvariant=\"bold-italic\">+</mo><msub><mi mathvariant=\"bold-italic\">f</mi><mi mathvariant=\"bold-italic\">n</mi></msub><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">n</mi></msub><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{g\\left(y\\right)=f_1\\left(x_1\\right)+f_2\\left(x_2\\right)+\\cdotp\\cdotp\\cdotp+f_n\\left(x_n\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">g</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">y</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathbf\">+</span><span class=\"mpunct mathbf\">⋅⋅⋅</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathbf\">+</span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1611em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1611em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[71,72]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">f</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mrow><mo fence=\"true\">(</mo><mo mathvariant=\"bold-italic\">⋅</mo><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f_{i}\\left(\\cdot\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathbf\">⋅</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span> <strong>: 单特征模型(single-feature) 、特征</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">i</mi></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5944em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>对应的形函数(shape function)</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[72,73]},"content":"<strong>可能非线性、复杂</strong>","children":[]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[73,74]},"content":"<strong>消除特征间的相互作用 <mark>(Disentangled representation ？)</mark></strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[74,75]},"content":"<strong>Lou, 基于有限大小的梯度提升树加性模型方法</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[75,76]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Intelligible models for classification and regression</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Intelligible models for classification and regression}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Intelligible models for classification and regression</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[76,77]},"content":"<strong>Ravikumar, 稀疏加性模型的高维非参数回归分类方法</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[77,78]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Sparse additive models</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Sparse additive models}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Sparse additive models</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[78,79]},"content":"<strong>结合稀疏线性建模和加性非参数回归</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[79,80]},"content":"<strong>解决了高维空间中加性模型的拟合问题</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[80,81]},"content":"<strong>基于</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">l</mi><mn mathvariant=\"bold\">1</mn></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{l_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0088em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>正则的稀疏性，可实现特征的有效选择</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[81,82]},"content":"<strong>Poulin, 加性模型的图形化解释</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[82,83]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Visual explanation of evidence with additive classifiers</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Visual explanation of evidence with additive classifiers}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Visual explanation of evidence with additive classifiers</span></span></span></span></span>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[83,84]},"content":"<strong>注意力机制(Attention Mechanism) <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[84,85]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Neural machine translation by jointly learning to align and translate</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Neural machine translation by jointly learning to align and translate}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Neural machine translation by jointly learning to align and translate</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[85,86]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Attention is all you need</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Attention is all you need}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Attention is all you need</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[86,87]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Retain: An interpretable predictive model for healthcare using reverse time attention mechanism</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Retain: An interpretable predictive model for healthcare using reverse time attention mechanism}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Retain: An interpretable predictive model for healthcare using reverse time attention mechanism</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[87,88]},"content":"神经网络模型由于<strong>模型结构复杂、算法透明性低</strong>，因此<strong>神经网络</strong>模型的<strong>自身可解释性只能</strong>通过<strong>额外引入可解释性模块 <mark>(只能？)</mark></strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[88,89]},"content":"<strong>注意力机制具有良好的可解释性</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[89,90]},"content":"<strong>注意力权重矩阵直接体现</strong>了<strong>模型在决策过程中感兴趣的区域</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[90,91]},"content":"<strong>NLP</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[91,92]},"content":"<strong>Bahdanau, AM结合ED</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[92,93]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Neural machine translation by jointly learning to align and translate</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Neural machine translation by jointly learning to align and translate}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Neural machine translation by jointly learning to align and translate</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[93,94]},"content":"<strong>En</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[94,95]},"content":"<strong>双向循环神经网络(Bi-RNN)将源语言编码到向量空间中</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[95,96]},"content":"<strong>De</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[96,97]},"content":"<strong>AM</strong>为<strong>解码器的隐藏状态分配不同的权重</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[97,98]},"content":"<strong>选择性地处理输入句子的不同部分</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[98,99]},"content":"<img src=\"AMweight_Visualization.png\" alt=\"\" title=\"可视化注意力权重\">","children":[]}]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[99,100]},"content":"<strong>Yang, 引入Hierarchical AM (HAM) 分层注意力机制到文本分类任务</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[100,101]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Hierarchical attention networks for document classification</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Hierarchical attention networks for document classification}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Hierarchical attention networks for document classification</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[101,102]},"content":"<strong>注意力权重量化了每一个词的重要性</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[102,103]},"content":"<img src=\"word_importance.png\" alt=\"\">","children":[]}]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[103,104]},"content":"<strong>CV</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[104,105]},"content":"<strong>Xu, <em>AM</em>用于看图说话(image caption)产生图片的描述</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[105,106]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Show, attend and tell: Neural image caption generation with visual attention</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Show, attend and tell: Neural image caption generation with visual attention}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Show, attend and tell: Neural image caption generation with visual attention</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[106,107]},"content":"<strong>CNN提取特征</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[107,108]},"content":"<strong>带AM的RNN生成描述</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[108,109]},"content":"<strong>注意力实现了单词与图片之间的对齐</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[109,110]},"content":"<strong>可视化注意力权重矩阵</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[110,111]},"content":"模型在<strong>生成每一个单词</strong>时所<strong>对应的感兴趣的图片区域</strong>","children":[{"type":"list_item","depth":11,"payload":{"lines":[111,112]},"content":"<img src=\"image_caption.png\" alt=\"\">","children":[]}]}]}]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[112,113]},"content":"<strong>Recommender System</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[113,114]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>NAIS: Neural attentive item similarity model for recommendation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {NAIS: Neural attentive item similarity model for recommendation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">NAIS: Neural attentive item similarity model for recommendation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[114,115]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Sequential recommender system based on hierarchical attention networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Sequential recommender system based on hierarchical attention networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Sequential recommender system based on hierarchical attention networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[115,116]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>ATRank: An attention-based user behavior modeling framework for recommendation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {ATRank: An attention-based user behavior modeling framework for recommendation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">ATRank: An attention-based user behavior modeling framework for recommendation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[116,117]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>NAIRS: A Neural Attentive Interpretable Recommendation System</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {NAIRS: A Neural Attentive Interpretable Recommendation System}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">NAIRS: A Neural Attentive Interpretable Recommendation System</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[117,118]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable convolutional neural networks with dual local and global attention for review rating prediction</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable convolutional neural networks with dual local and global attention for review rating prediction}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable convolutional neural networks with dual local and global attention for review rating prediction</span></span></span></span></span>","children":[]}]}]}]},{"type":"list_item","depth":4,"payload":{"lines":[118,119]},"content":"<strong>事后(post-hoc)可解释性</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[119,120]},"content":"通过<strong>开发可解释性技术解释已训练好的机器学习模型</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[120,121]},"content":"<img src=\"post_hoc_1.png\" alt=\"\" title=\"事后可解释性_1\">","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[121,122]},"content":"<img src=\"post_hoc_2.png\" alt=\"\" title=\"事后可解释性_2\">","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[122,123]},"content":"<strong>全局可解释性(global interpretability)</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[123,124]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A survey of methods for explaining black box models</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A survey of methods for explaining black box models}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A survey of methods for explaining black box models</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[124,125]},"content":"理解复杂模型背后的<strong>整体逻辑以及内部的工作机制</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[125,126]},"content":"<strong>规则提取 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[126,127]},"content":"<strong>利用可理解的规则集合生成可解释的符号描述，或从中提取可解释模(如决策树、基于规则的模型等)</strong>，使之具有<strong>与原模型相当的决策能力</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[127,128]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Survey and critique of techniques for extracting rules from trained artificial neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Survey and critique of techniques for extracting rules from trained artificial neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Survey and critique of techniques for extracting rules from trained artificial neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[128,129]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained artificial neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained artificial neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained artificial neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[129,130]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>DEDEC: A methodology for extracting rules from trained artificial neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {DEDEC: A methodology for extracting rules from trained artificial neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">DEDEC: A methodology for extracting rules from trained artificial neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[130,131]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Rule generation from neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Rule generation from neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Rule generation from neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[131,132]},"content":"<strong>针对树融合(tree ensemble)模型</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[132,133]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpreting tree ensembles within trees</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpreting tree ensembles within trees}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpreting tree ensembles within trees</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[133,134]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Rule extraction from decision trees ensembles: New algorithms based on heuristic search and sparse group lasso methods</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Rule extraction from decision trees ensembles: New algorithms based on heuristic search and sparse group lasso methods}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Rule extraction from decision trees ensembles: New algorithms based on heuristic search and sparse group lasso methods</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[134,135]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Rule extraction from random forest: The RF+HC methods</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Rule extraction from random forest: The RF+HC methods}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Rule extraction from random forest: The RF+HC methods</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[135,136]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Making tree ensembles interpretable: A Bayesian model selection approach</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Making tree ensembles interpretable: A Bayesian model selection approach}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Making tree ensembles interpretable: A Bayesian model selection approach</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[136,137]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Making tree ensembles interpretable</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Making tree ensembles interpretable}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Making tree ensembles interpretable</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[137,138]},"content":"一个集成的树模型<strong>通常由多个决策树构成</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[138,139]},"content":"<strong>每棵树</strong>的<strong>根节点到叶子节点</strong>的<strong>每一条路径</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[139,140]},"content":"<strong>一条决策规则</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[140,141]},"content":"<strong>每一棵决策树中提取的规则进行组合</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[141,142]},"content":"基于<strong>规则长度、规则频率、误差等</strong>指标<strong>对提取的规则进行排序</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[142,143]},"content":"<strong>规则长度</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[143,144]},"content":"<strong>规则的复杂度</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[144,145]},"content":"<strong>规则频率</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[145,146]},"content":"<strong>满足规则的数据实例的比例</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[146,147]},"content":"<strong>误差</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[147,148]},"content":"<strong>规则的决策能力</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[148,149]},"content":"<strong>基于排序结果</strong>，<strong>对</strong>规则中的<strong>无关项和冗余项</strong>进行<strong>剪枝</strong>并<strong>选择</strong>一组相关的<strong>非冗余规则</strong>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[149,150]},"content":"<strong>针对神经网络模型 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[150,151]},"content":"<strong>分解法(decompositional method)</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[151,152]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Global model interpretation via recursive partitioning</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Global model interpretation via recursive partitioning}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Global model interpretation via recursive partitioning</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[152,153]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A systematic method for decompositional rule extraction from neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A systematic method for decompositional rule extraction from neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A systematic method for decompositional rule extraction from neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[153,154]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Decompositional rules extraction methods from neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Decompositional rules extraction methods from neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Decompositional rules extraction methods from neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[154,155]},"content":"<strong>要求神经网络透明</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[155,156]},"content":"注重从受训神经网络中<strong>提取单个单元(如隐含单元、输出单元)层次上规则 <mark>(Disentangled representation ？)</mark></strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[156,157]},"content":"<strong>每一个隐含单元和输出单元的计算结果</strong>都能映射成一个<strong>对应于一条规则的二进制结果</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[157,158]},"content":"每一个<strong>隐含单元或输出单元</strong>都可以被解释为<strong>一个阶跃函数或一条布尔规则</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[158,159]},"content":"<strong>教学法(pedagogical method)</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[159,160]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Using sampling and queries to extract rules from trained neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Using sampling and queries to extract rules from trained neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Using sampling and queries to extract rules from trained neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[160,161]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Extracting symbolic rules from trained neural network ensembles</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Extracting symbolic rules from trained neural network ensembles}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Extracting symbolic rules from trained neural network ensembles</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[161,162]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Active learning-based pedagogical rule extraction</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Active learning-based pedagogical rule extraction}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Active learning-based pedagogical rule extraction</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[162,163]},"content":"<strong>神经网络视为黑盒</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[163,164]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>MAGIX: Model agnostic globally interpretable explanations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {MAGIX: Model agnostic globally interpretable explanations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">MAGIX: Model agnostic globally interpretable explanations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[164,165]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable and explorable approximations of black box models</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable and explorable approximations of black box models}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable and explorable approximations of black box models</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[165,166]},"content":"<strong>只能操纵</strong>模型的<strong>输入和输出</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[166,167]},"content":"提取将<strong>输入直接映射到输出的规则</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[167,168]},"content":"<strong>结合符号学习算法</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[168,169]},"content":"利用<strong>受训神经网络来为学习算法生成样本</strong>，最后<strong>从生成的样例中提取规则</strong>","children":[]}]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[169,170]},"content":"<strong>不够精确，只能提供近似解释，可解释性的质量受规则本身复杂度的制约</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[170,171]},"content":"<strong>模型蒸馏 (Knowledge Distillation) <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[171,172]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Improving the interpretability of deep neural networks with knowledge distillation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Improving the interpretability of deep neural networks with knowledge distillation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Improving the interpretability of deep neural networks with knowledge distillation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[172,173]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Model compression</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Model compression}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Model compression</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[173,174]},"content":"<strong>降低模型复杂度</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[174,175]},"content":"<strong>结构紧凑的学生模型(student model)作为结构复杂的教师模型(teacher model)的全局近似</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[175,176]},"content":"<strong>如何保留学习到的知识和泛化能力</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[176,177]},"content":"<strong>学生模型用可解释性好的模型(线性模型、决策树、广义加性模型以及浅层神经网络等)</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[177,178]},"content":"<strong>Hinton, 知识蒸馏</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[178,179]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Distilling the knowledge in a neural network</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Distilling the knowledge in a neural network}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Distilling the knowledge in a neural network</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[179,180]},"content":"<strong>软目标辅助硬目标训练学生模型</strong>","children":[{"type":"list_item","depth":11,"payload":{"lines":[180,181]},"content":"<strong>软目标</strong>","children":[{"type":"list_item","depth":12,"payload":{"lines":[181,182]},"content":"<strong>教师模型的分类概率值</strong>","children":[]},{"type":"list_item","depth":12,"payload":{"lines":[182,183]},"content":"包含的<strong>信息量大</strong>，体现了<strong>不同类别之间相关关系</strong>的信息","children":[]}]},{"type":"list_item","depth":11,"payload":{"lines":[183,184]},"content":"<strong>硬目标</strong>","children":[{"type":"list_item","depth":12,"payload":{"lines":[184,185]},"content":"<strong>原始数据的类别信息</strong>","children":[]}]}]},{"type":"list_item","depth":10,"payload":{"lines":[185,186]},"content":"<strong>教师模型生成软目标，最小化软目标和硬目标的联合损失函数</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">L</mi><mtext>stdudent</mtext></msub><mo lspace=\"0em\" rspace=\"0em\">=</mo><mi mathvariant=\"bold-italic\">α</mi><msup><mi mathvariant=\"bold-italic\">L</mi><mtext>(soft)</mtext></msup><mo mathvariant=\"bold-italic\">+</mo><mo stretchy=\"false\">(</mo><mn mathvariant=\"bold\">1</mn><mo mathvariant=\"bold-italic\">−</mo><mi mathvariant=\"bold-italic\">α</mi><mo stretchy=\"false\">)</mo><msup><mi mathvariant=\"bold-italic\">L</mi><mtext>(hard)</mtext></msup></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{L_\\text{stdudent}{ = }\\alpha L^{\\text{(soft)}} + (1- \\alpha)L^{\\text{(hard)}}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">stdudent</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mrel mathbf\">=</span></span><span class=\"mord boldsymbol\">α</span><span class=\"mord\"><span class=\"mord boldsymbol\">L</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.888em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">(soft)</span></span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mopen mathbf\">(</span><span class=\"mord mathbf\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord boldsymbol\">α</span><span class=\"mclose mathbf\">)</span><span class=\"mord\"><span class=\"mord boldsymbol\">L</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.888em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">(hard)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 来<strong>训练学生模型</strong>","children":[{"type":"list_item","depth":11,"payload":{"lines":[186,187]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msup><mi mathvariant=\"bold-italic\">L</mi><mtext>(soft)</mtext></msup></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{L^{\\text{(soft)}}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.888em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">L</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.888em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">(soft)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":12,"payload":{"lines":[187,188]},"content":"<strong>软目标损失</strong>","children":[]},{"type":"list_item","depth":12,"payload":{"lines":[188,189]},"content":"<strong>要求学生模型生成的软目标</strong>与<strong>教师模型生成的软目标</strong>要<strong>尽可能的接近</strong>，保证学生模型能<strong>有效地学习教师模型中的暗知识(dark knowledge)</strong>","children":[]}]},{"type":"list_item","depth":11,"payload":{"lines":[189,190]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msup><mi mathvariant=\"bold-italic\">L</mi><mtext>(hard)</mtext></msup></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{L^{\\text{(hard)}}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.888em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">L</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.888em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">(hard)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":12,"payload":{"lines":[190,191]},"content":"<strong>硬目标损失</strong>","children":[]},{"type":"list_item","depth":12,"payload":{"lines":[191,192]},"content":"<strong>要求学生模型</strong>能够<strong>保留</strong>教师模型<strong>良好的决策性能</strong>","children":[]}]}]}]},{"type":"list_item","depth":9,"payload":{"lines":[192,193]},"content":"<strong>Frosst, 决策树模拟</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[193,194]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Distilling a neural network into a soft decision tree</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Distilling a neural network into a soft decision tree}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Distilling a neural network into a soft decision tree</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[194,195]},"content":"<strong>Tan, GAM模拟</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[195,196]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning global additive explanations for neural nets using model distillation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning global additive explanations for neural nets using model distillation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning global additive explanations for neural nets using model distillation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[196,197]},"content":"提出利用KD来学习<strong>描述输入特征与复杂模型的预测</strong>之间<strong>关系</strong>的<strong>全局加性模型</strong>，并<strong>基于加性模型</strong>对复杂模型进行<strong>全局解释</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[197,198]},"content":"<strong>Che, 模型蒸馏的可解释方法应用于医疗诊断模型</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[198,199]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable deep models for ICU outcome prediction</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable deep models for ICU outcome prediction}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable deep models for ICU outcome prediction</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[199,200]},"content":"<strong>梯度提升树</strong>进行知识蒸馏的方式来<strong>学习可解释模型</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[200,201]},"content":"在<strong>急性肺损伤</strong>病人<strong>无呼吸机天数预测</strong>任务中效果优异","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[201,202]},"content":"<strong>Xu, <em>Darksight</em> <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[202,203]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpreting deep classifier by visual distillation of dark knowledge</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpreting deep classifier by visual distillation of dark knowledge}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpreting deep classifier by visual distillation of dark knowledge</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[203,204]},"content":"<strong>模型蒸馏</strong>从<strong>黑盒模型</strong>中<strong>提取暗知识</strong>，并以<strong>可视化</strong>的形式对提取的<strong>暗知识</strong>进行呈现","children":[]}]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[204,205]},"content":"<strong>实现简单，易于理解</strong>，且不依赖待解释模型的具体结构信息，因而作为一种<strong>模型无关</strong>的解释方法，常被用于解释黑盒机器学习模型","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[205,206]},"content":"蒸馏模型<strong>只是</strong>对原始复杂模型的<strong>一种全局近似</strong>，它们之间始终存在差距．因此，基于蒸馏模型所做出的解释<strong>不一定能反映</strong>待解释模型的<strong>真实行为</strong>．此外，<strong>知识蒸馏过程通常不可控</strong>，<strong>无法保障</strong>待解释模型从海量数据中<strong>学到的知识有效地迁移到蒸馏模型</strong>中，因而导致解释结果<strong>质量较低</strong>无法满足精确解释的需要","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[206,207]},"content":"<strong>激活最大化 (activation maximization, AM)</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[207,208]},"content":"考虑到<strong>数据集</strong>中<strong>存在偏差</strong>，<strong>模型精度无法保证模型表征的可靠性</strong>，也<strong>无法确定 DNN</strong> 用于<strong>预测</strong>的<strong>内部工作模式</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[208,209]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Examining CNN representations with respect to dataset bias</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Examining CNN representations with respect to dataset bias}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Examining CNN representations with respect to dataset bias</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[209,210]},"content":"<strong>DNN中每一个隐含层的神经元所捕获的表征</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[210,211]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable convolutional neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable convolutional neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable convolutional neural networks</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[211,212]},"content":"在<strong>特定的层</strong>上找到<strong>神经元的首选输入最大化神经元激活</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[212,213]},"content":"通过寻找<strong>有界范数的输入模式</strong>，<strong>最大限度</strong>地<strong>激活</strong>给定的<strong>隐藏单元</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[213,214]},"content":"<strong>一个单元最大限度地响应的输入模式可能</strong>是一个单元<strong>正在做什么的良好的一阶表示</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[214,215]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Visualizing higher-layer features of a deep network</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Visualizing higher-layer features of a deep network}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Visualizing higher-layer features of a deep network</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[215,216]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>On the analysis and interpretation of inhomogeneous quadratic forms as receptive fields</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {On the analysis and interpretation of inhomogeneous quadratic forms as receptive fields}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">On the analysis and interpretation of inhomogeneous quadratic forms as receptive fields</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[216,217]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Methods for interpreting and understanding deep neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Methods for interpreting and understanding deep neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Methods for interpreting and understanding deep neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[217,218]},"content":"<strong>可定义为优化问题: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msup><mi mathvariant=\"bold-italic\">x</mi><mo mathvariant=\"bold-italic\" lspace=\"0em\" rspace=\"0em\">∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi mathvariant=\"bold-italic\">x</mi></msub><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">f</mi><mi mathvariant=\"bold-italic\">l</mi></msub><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo mathvariant=\"bold-italic\">−</mo><mi mathvariant=\"bold-italic\">λ</mi><msup><mrow><mo fence=\"true\">∥</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">∥</mo></mrow><mn mathvariant=\"bold\">2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x^{*}=\\arg\\max_{x}(f_{l}(x)-\\lambda\\left\\|x\\right\\|^{2})}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.204em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6936em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">∗</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mop\"><span class=\"mathbf\">a</span><span class=\"mathbf\">r</span><span class=\"mathbf\" style=\"margin-right:0.01597em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop\"><span class=\"mathbf\">m</span><span class=\"mathbf\">a</span><span class=\"mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1611em;\"><span style=\"top:-2.55em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">x</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen mathbf\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\" style=\"margin-right:0.0088em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord boldsymbol\">λ</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">∥</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose delimcenter\" style=\"top:0em;\">∥</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mclose mathbf\">)</span></span></span></span></span></span></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[218,219]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">f</mi><mi mathvariant=\"bold-italic\">l</mi></msub><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f_{l}\\left(x\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\" style=\"margin-right:0.0088em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":10,"payload":{"lines":[219,220]},"content":"<strong>DNN第</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">l</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{l}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span></span></span></span></span></span> <strong>层某一个神经元</strong>在<strong>当前输入</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span></span></span></span></span></span> 下的<strong>激活值</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[220,221]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">λ</mi><msup><mrow><mo fence=\"true\">∥</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">∥</mo></mrow><mn mathvariant=\"bold\">2</mn></msup></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{\\lambda\\left\\|x\\right\\|^{2}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.204em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">λ</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">∥</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose delimcenter\" style=\"top:0em;\">∥</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":10,"payload":{"lines":[221,222]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">l</mi><mn mathvariant=\"bold\">2</mn></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{l_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0088em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>正则</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[222,223]},"content":"<strong>通过梯度上升求解</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[223,224]},"content":"<strong>可视化生成的原型样本</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msup><mi mathvariant=\"bold-italic\">x</mi><mo mathvariant=\"bold-italic\" lspace=\"0em\" rspace=\"0em\">∗</mo></msup></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x^{*}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6936em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6936em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[224,225]},"content":"<strong>虽然原理简单，但实际不易实现</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[225,226]},"content":"<strong>样本搜索空间很大</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[226,227]},"content":"<strong>优化过程可能产生含有噪声和高频模式的不现实图像</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[227,228]},"content":"<strong>难以理解</strong>","children":[]}]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[228,229]},"content":"<strong>故必须采用 <mark>自然图像先验约束（？）</mark></strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[229,230]},"content":"<strong>人工构造先验</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[230,231]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Understanding deep image representations by inverting them</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Understanding deep image representations by inverting them}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Understanding deep image representations by inverting them</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[231,232]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Plug and play generative networks: Conditional iterative generation of images in latent space</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Plug and play generative networks: Conditional iterative generation of images in latent space}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Plug and play generative networks: Conditional iterative generation of images in latent space</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[232,233]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">α</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{\\alpha}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">α</span></span></span></span></span></span> <strong>范数</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[233,234]},"content":"<strong>高斯模糊</strong>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[234,235]},"content":"<strong>Nguyen, 生成对抗网络结合激活最大化生成原型样本</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[235,236]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Synthesizing the preferred inputs for neurons in neural networks via deep generator networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Synthesizing the preferred inputs for neurons in neural networks via deep generator networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Synthesizing the preferred inputs for neurons in neural networks via deep generator networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[236,237]},"content":"<strong>优化问题重定义：</strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msup><mi mathvariant=\"bold-italic\">z</mi><mo mathvariant=\"bold-italic\">∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mrow><mi mathvariant=\"bold-italic\">z</mi><mo>∈</mo><mi mathvariant=\"bold-italic\">Z</mi></mrow></msub><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">f</mi><mi mathvariant=\"bold-italic\">l</mi></msub><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">g</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo mathvariant=\"bold-italic\">−</mo><mi mathvariant=\"bold-italic\">λ</mi><msup><mrow><mo fence=\"true\">∥</mo><mi mathvariant=\"bold-italic\">z</mi><mo fence=\"true\">∥</mo></mrow><mn mathvariant=\"bold\">2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{z^*=\\arg\\max_{z\\in Z}(f_l(g(z))-\\lambda\\left\\|z\\right\\|^2)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.204em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6936em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mathbf mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mop\"><span class=\"mathbf\">a</span><span class=\"mathbf\">r</span><span class=\"mathbf\" style=\"margin-right:0.01597em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop\"><span class=\"mathbf\">m</span><span class=\"mathbf\">a</span><span class=\"mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3303em;\"><span style=\"top:-2.55em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\" style=\"margin-right:0.04213em;\">z</span><span class=\"mrel mathbf mtight\">∈</span><span class=\"mord boldsymbol mtight\" style=\"margin-right:0.06979em;\">Z</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2099em;\"><span></span></span></span></span></span></span><span class=\"mopen mathbf\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\" style=\"margin-right:0.0088em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">g</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span><span class=\"mclose mathbf\">))</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord boldsymbol\">λ</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">∥</span><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span><span class=\"mclose delimcenter\" style=\"top:0em;\">∥</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose mathbf\">)</span></span></span></span></span></span>","children":[{"type":"list_item","depth":9,"payload":{"lines":[237,238]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">f</mi><mi mathvariant=\"bold-italic\">l</mi></msub><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">g</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">z</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f_l(g(z))}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.1104em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\" style=\"margin-right:0.0088em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">g</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span><span class=\"mclose mathbf\">))</span></span></span></span></span></span>","children":[{"type":"list_item","depth":10,"payload":{"lines":[238,239]},"content":"<strong>解码器与原神经元激活值的结合</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[239,240]},"content":"<strong>不直接优化图像</strong>，转而<strong>优化代码空间</strong>以找到可以<strong>最大化神经元激活的解</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msup><mi mathvariant=\"bold-italic\">z</mi><mo mathvariant=\"bold-italic\">∗</mo></msup></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{z^*}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6936em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6936em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mathbf mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[240,241]},"content":"<strong>解码得到原型样本</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msup><mi mathvariant=\"bold-italic\">x</mi><mo mathvariant=\"bold-italic\">∗</mo></msup><mo>=</mo><mi mathvariant=\"bold-italic\">g</mi><mrow><mo fence=\"true\">(</mo><msup><mi mathvariant=\"bold-italic\">z</mi><mo mathvariant=\"bold-italic\">∗</mo></msup><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x^* = g\\left(z^*\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6936em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mathbf mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">g</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6936em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mathbf mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":9,"payload":{"lines":[241,242]},"content":"<img src=\"class_discriminative_GM_AM.png\" alt=\"\" title=\"利用生成模型与激活最大化相结合生成的类别对应原型样本\">","children":[]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[242,243]},"content":"<strong>模型相关，解释结果更准确，可视化易于理解</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[243,244]},"content":"<strong>优化过程中</strong>的<strong>噪音和不确定性可能导致</strong>产生的<strong>原型样本难以解释</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[244,245]},"content":"虽然<strong>构造自然图像先验约束优化过程</strong>可以<strong>解决</strong>，<strong>但</strong>如何构造更好的<strong>自然图像先验本身</strong>就是一大<strong>难题</strong>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[245,246]},"content":"<strong>只能用于优化连续性数据</strong>，<strong>无法直接应用于</strong>诸如<strong>文本、图数据</strong>等离散型数据","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[246,247]},"content":"<strong>局部可解释性(local interpretability)</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[247,248]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>How to explain individual classification decisions</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {How to explain individual classification decisions}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">How to explain individual classification decisions</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[248,249]},"content":"理解机器学习模型<strong>针对每一个输入样本的决策过程和决策依据</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[249,250]},"content":"<strong>以输入样本为导向</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[250,251]},"content":"通常通过分析<strong>输入样本</strong>的<strong>每一维特征对</strong>模型<strong>最终决策</strong>结果<strong>的贡献</strong>来实现","children":[{"type":"list_item","depth":7,"payload":{"lines":[251,252]},"content":"<strong>敏感性分析</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[252,253]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Sensitivity Analysis in Practice: A Guide to Assessing Scientific Models</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Sensitivity Analysis in Practice: A Guide to Assessing Scientific Models}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Sensitivity Analysis in Practice: A Guide to Assessing Scientific Models</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[253,254]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Sensitivity Analysis in Linear Regression</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Sensitivity Analysis in Linear Regression}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Sensitivity Analysis in Linear Regression</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[254,255]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Importance measures in global sensitivity analysis of nonlinear models</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Importance measures in global sensitivity analysis of nonlinear models}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Importance measures in global sensitivity analysis of nonlinear models</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[255,256]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A quantitative model-independent method for global sensitivity analysis of model output</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A quantitative model-independent method for global sensitivity analysis of model output}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A quantitative model-independent method for global sensitivity analysis of model output</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[256,257]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Determining the significance of input parameters using sensitivity analysis</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Determining the significance of input parameters using sensitivity analysis}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Determining the significance of input parameters using sensitivity analysis</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[257,258]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Sensitivity analysis applied to artificial neural networks: What has my neural network actually learned?</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Sensitivity analysis applied to artificial neural networks: What has my neural network actually learned?}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Sensitivity analysis applied to artificial neural networks: What has my neural network actually learned?</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[258,259]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Ranking importance of input parameters of neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Ranking importance of input parameters of neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Ranking importance of input parameters of neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[259,260]},"content":"<strong>给定假设</strong>下，<strong>定量分析相关自变量</strong>发生某种<strong>变化对</strong>某一<strong>特定因变量</strong>的<strong>影响程度</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[260,261]},"content":"<strong>模型相关</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[261,262]},"content":"<strong>局部梯度信息</strong>评估<strong>特征与决策结果的相关性</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[262,263]},"content":"<strong>相关性：</strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">R</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">)</mo></mrow><mo>=</mo><msup><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi mathvariant=\"bold\">∂</mi><mi mathvariant=\"bold-italic\">f</mi><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">)</mo></mrow></mrow><mrow><mi mathvariant=\"bold\">∂</mi><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">i</mi></msub></mrow></mfrac><mo fence=\"true\">)</mo></mrow><mn mathvariant=\"bold\">2</mn></msup></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{R_i\\left(x\\right)=\\left(\\frac{\\partial f\\left(x\\right)}{\\partial x_i}\\right)^2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.004em;vertical-align:-0.65em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.00421em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:-0.0042em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\" style=\"margin-right:0.06389em;\">∂</span><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3496em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1504em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\" style=\"margin-right:0.06389em;\">∂</span><span class=\"mord boldsymbol mtight\" style=\"margin-right:0.11042em;\">f</span><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord boldsymbol mtight\">x</span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4503em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.354em;\"><span style=\"top:-3.6029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":10,"payload":{"lines":[263,264]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f(x)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span></span></span></span></span></span>","children":[{"type":"list_item","depth":11,"payload":{"lines":[264,265]},"content":"<strong>决策函数</strong>","children":[]}]},{"type":"list_item","depth":10,"payload":{"lines":[265,266]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">i</mi></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5944em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":11,"payload":{"lines":[266,267]},"content":"<strong>待解释样本</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span></span></span></span></span></span> 的<strong>第</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">i</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6933em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">i</span></span></span></span></span></span> <strong>维特征</strong>","children":[]}]},{"type":"list_item","depth":10,"payload":{"lines":[267,268]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">R</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{R_i\\left(x\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.00421em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:-0.0042em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":11,"payload":{"lines":[268,269]},"content":"可看作<strong>模型梯度的</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">l</mi><mn mathvariant=\"bold\">2</mn></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{l_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0088em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>范数的分解</strong>","children":[{"type":"list_item","depth":12,"payload":{"lines":[269,270]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msubsup><mo>∑</mo><mrow><mi mathvariant=\"bold-italic\">i</mi><mo>=</mo><mn mathvariant=\"bold\">1</mn></mrow><mi mathvariant=\"bold-italic\">d</mi></msubsup><msub><mi mathvariant=\"bold-italic\">R</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo>∥</mo><mi mathvariant=\"bold\">∇</mi><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><msup><mo>∥</mo><mn mathvariant=\"bold\">2</mn></msup></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{\\sum_{i=1}^dR_i(x) = \\parallel\\nabla f(x)\\parallel^{2}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2887em;vertical-align:-0.2997em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.989em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">i</span><span class=\"mrel mathbf mtight\">=</span><span class=\"mord mathbf mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.00421em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:-0.0042em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=∥</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathbf\">∇</span><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\"><span class=\"mrel mathbf\">∥</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[]}]}]}]},{"type":"list_item","depth":9,"payload":{"lines":[270,271]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">R</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{R_i\\left(x\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.00421em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:-0.0042em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span> <strong>可通过梯度反传求解</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[271,272]},"content":"<strong>模型无关</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[272,273]},"content":"<strong>待解释模型可看作黑盒，无需模型梯度信息，只关注待解释样本特征值变化对模型最终决策的影响</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[273,274]},"content":"<strong>Robnik-Sikonja</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[274,275]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Explaining classifications for individual instances</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Explaining classifications for individual instances}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Explaining classifications for individual instances</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[275,276]},"content":"<strong>分解输入样本单个属性值的预测</strong>的方式来观察属性值<strong>对</strong>该样本<strong>预测结果的影响</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[276,277]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">R</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo mathvariant=\"bold-italic\">−</mo><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold\">\\</mi><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{R_i(x)=f(x)-f(x\\backslash x_{i})}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.00421em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:-0.0042em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mord mathbf\">\\</span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose mathbf\">)</span></span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[277,278]},"content":"<strong>Liu, 限制支持域集</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[278,279]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>What has my classifier learned? Visualizing the classification rules of bag-of-feature model by support region detection</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {What has my classifier learned? Visualizing the classification rules of bag-of-feature model by support region detection}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">What has my classifier learned? Visualizing the classification rules of bag-of-feature model by support region detection</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[279,280]},"content":"<strong>限制支持域集</strong>","children":[{"type":"list_item","depth":11,"payload":{"lines":[280,281]},"content":"一组受<strong>大小限制</strong>且<strong>不重叠</strong>的<strong>区域</strong>","children":[]},{"type":"list_item","depth":11,"payload":{"lines":[281,282]},"content":"<strong>删除任何一个区域</strong>将会<strong>导致</strong>模型<strong>分类出错</strong>","children":[]}]}]},{"type":"list_item","depth":9,"payload":{"lines":[282,283]},"content":"<strong>Fong, 基于有意义扰动的敏感性分析方法</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[283,284]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable explanations of black boxes by meaningful perturbation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable explanations of black boxes by meaningful perturbation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable explanations of black boxes by meaningful perturbation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[284,285]},"content":"<strong>添加扰动或删除</strong>待解释图片的<strong>不同区域</strong>","children":[{"type":"list_item","depth":11,"payload":{"lines":[285,286]},"content":"<strong>最小化</strong>模型目标类别<strong>分类概率</strong>的方式<strong>学习</strong>一个<strong>显著性掩码</strong>","children":[{"type":"list_item","depth":12,"payload":{"lines":[286,287]},"content":"识别对模型决策<strong>结果影响最大的图像部分</strong>","children":[]},{"type":"list_item","depth":12,"payload":{"lines":[287,288]},"content":"<strong>可视化显著性掩码</strong>","children":[{"type":"list_item","depth":13,"payload":{"lines":[288,289]},"content":"<img src=\"saliency_mask.png\" alt=\"\" title=\"通过图像模糊的方式最小化分类概率来学习显著性掩码\">","children":[]}]}]}]}]},{"type":"list_item","depth":9,"payload":{"lines":[289,290]},"content":"<strong>Li</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[290,291]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Understanding neural networks through representation erasure</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Understanding neural networks through representation erasure}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Understanding neural networks through representation erasure</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[291,292]},"content":"观察<strong>修改或删除特征子集</strong>前后模型<strong>决策结果</strong>的相应<strong>变化</strong>的方式来<strong>推断</strong>待解释样本的<strong>决策特征</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[292,293]},"content":"<strong>解释的是决策函数</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f(x)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose mathbf\">)</span></span></span></span></span></span> <strong>局部变化对决策结果的影响，而不是决策函数本身</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[293,294]},"content":"<strong>只能</strong>捕获<strong>单个特征对</strong>最终决策<strong>结果</strong>的<strong>影响程度</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[294,295]},"content":"<strong>相关性分值</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">R</mi><mi mathvariant=\"bold-italic\">i</mi></msub><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{R_i\\left(x\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.00421em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3353em;\"><span style=\"top:-2.55em;margin-left:-0.0042em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord boldsymbol\">x</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span> 对应的<strong>热力图</strong>在<strong>空间上</strong>是<strong>离散</strong>而不连续的","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[295,296]},"content":"<strong>解释结果</strong>通常<strong>相对粗糙</strong>且<strong>难以理解，无法解释特征之间的相关关系对</strong>最终决策<strong>结果的影响</strong>","children":[]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[296,297]},"content":"<strong>局部近似</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[297,298]},"content":"给定一个输入实例，模型针对<strong>该实例以及该实例邻域内样本的决策边界可以通过可解释的白盒模型来近似</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[298,299]},"content":"<strong>Ribeiro, <em>LIME</em> <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[299,300]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Why should I trust you? Explaining the predictions of any classifier</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Why should I trust you? Explaining the predictions of any classifier}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Why should I trust you? Explaining the predictions of any classifier</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[300,301]},"content":"<strong>神经网络的局部线性假设</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[301,302]},"content":"在整个数据空间中，待解释模型的<strong>决策边界可以任意的复杂</strong>，<strong>但</strong>模型<strong>针对某一特定实例</strong>的<strong>决策边界通常</strong>是<strong>简单</strong>的，<strong>甚至</strong>是<strong>近线性</strong>的","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[302,303]},"content":"利用<strong>该实例以及一组近邻训练</strong>一个<strong>回归模型来拟合待解释模型的局部边界</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[303,304]},"content":"<strong>线性模型</strong>的<strong>权重系数</strong>直接体现了<strong>当前决策</strong>中<strong>该实例</strong>的<strong>每一维特征重要性</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[304,305]},"content":"<strong>Guidotti, <em>LORE</em></strong>, 适用于<strong>关系表数据</strong>的基于<strong>局部规则</strong>的<strong>黑盒模型决策结果解释方法</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[305,306]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Local rule-based explanations of black box decision systems</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Local rule-based explanations of black box decision systems}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Local rule-based explanations of black box decision systems</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[306,307]},"content":"<strong>二分类模型</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">f</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span></span></span></span></span></span> <strong>，由</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">f</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span></span></span></span></span></span> <strong>标记的实例</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[307,308]},"content":"<strong><em>ad-hoc</em> 遗传算法生成给定实例</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span></span></span></span></span></span> 的<strong>一组平衡邻居实例</strong>来<strong>构建</strong>一个<strong>简单</strong>的、<strong>可解释</strong>的<strong>预测模型，逼近针对实例</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span></span></span></span></span></span> <strong>的决策边界</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[308,309]},"content":"从<strong>生成的实例</strong>集合<strong>中提取一个决策树模型，并提取规则作为实例</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span></span></span></span></span></span> <strong>分类结果的局部解释</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[309,310]},"content":"<strong>Ribeiro, <em>Anchor</em> <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[310,311]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Anchors: High-precision model-agnostic explanations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Anchors: High-precision model-agnostic explanations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Anchors: High-precision model-agnostic explanations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[311,312]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Nothing else matters: Model-agnostic explanations by identifying prediction invariance</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Nothing else matters: Model-agnostic explanations by identifying prediction invariance}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Nothing else matters: Model-agnostic explanations by identifying prediction invariance</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[312,313]},"content":"<strong><em>if-then</em> 规则</strong>来<strong>逼近</strong>待解释模型的<strong>局部边界</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[313,314]},"content":"<strong>直观、易于理解</strong>，而且<strong>解释覆盖范围清晰</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[314,315]},"content":"<strong><em>LIME</em>, <em>LORE</em>, <em>Anchor</em></strong>, 需<strong>假设输入样本特征相互独立，无法准确解释 <em>RNN</em> 等</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[315,316]},"content":"<strong>Guo, <em>LEMNA</em></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[316,317]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Lemna: Explaining deep learning based security applications</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Lemna: Explaining deep learning based security applications}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Lemna: Explaining deep learning based security applications</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[317,318]},"content":"<strong>假设</strong>待解释模型的<strong>局部边界</strong>是<strong>非线性</strong>的","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[318,319]},"content":"<strong>训练混合回归模型</strong>，<strong>保证解释</strong>的<strong>保真度</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[319,320]},"content":"引入<strong>融合 <em>(Fused) Lasso</em> 正则处理 <em>RNN</em> 特征依赖</strong>问题","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[320,321]},"content":"<strong>实现简单、易于理解、不依赖模型具体结构</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[321,322]},"content":"<strong>只是局部近似，无法解释整体决策</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[322,323]},"content":"对于<strong>不同的输入实例</strong>，需要<strong>重新训练</strong>模型拟合，<strong>效率不高</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[323,324]},"content":"<strong>需要</strong>待解释实例的<strong>特征相互独立</strong>，<strong>无法解释特征之间相关关系</strong>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[324,325]},"content":"<strong>反向传播 (back propagation, BP)</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[325,326]},"content":"<strong>Simonyan, <em>Grad</em></strong>, <strong>利用反向传播推断特征重要性</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[326,327]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Deep inside convolutional networks: Visualising image classification models and saliency maps</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Deep inside convolutional networks: Visualising image classification models and saliency maps}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Deep inside convolutional networks: Visualising image classification models and saliency maps</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[327,328]},"content":"利用 <strong><em>BP</em> 计算</strong>模型的<strong>输出相对于输入</strong>图片的<strong>梯度</strong>来求解该输入图片所对应的<strong>分类显著图(Saliency Map)</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[328,329]},"content":"<strong>Zeiler, <em>DeconvNet</em></strong>, <strong>反卷积网络</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[329,330]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Visualizing and understanding convolutional networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Visualizing and understanding convolutional networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Visualizing and understanding convolutional networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[330,331]},"content":"反向传播一个重要信号时，<strong>当且仅当信号值为负</strong>，<strong>进入 ReLU 的重要信号被置零</strong>，而不<strong>考虑前向传播</strong>过程中<strong>输入到 ReLU 的信号的符号</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[331,332]},"content":"<strong>Springenberg, <em>GuidedBP</em></strong>, <strong>结合 <em>Grad</em> 和 <em>DeconvNet</em></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[332,333]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Striving for simplicity: The all convolutional net</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Striving for simplicity: The all convolutional net}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Striving for simplicity: The all convolutional net</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[333,334]},"content":"<strong>丢弃负值</strong>来<strong>修改 ReLU 函数梯度</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[334,335]},"content":"<strong>Sundararajan, <em>Integrated</em></strong>, <strong>集成梯度方法 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[335,336]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Gradients of counterfactuals</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Gradients of counterfactuals}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Gradients of counterfactuals</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[336,337]},"content":"<strong>计算输入从某些起始值按比例放大到当前值的梯度的积分代替单一梯度</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[337,338]},"content":"<strong>有效解决 DNN 神经元饱和</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[338,339]},"content":"<strong>DNN 神经元饱和: 梯度信息无法反映特征重要性</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[339,340]},"content":"<strong><mark>以上4种得到的显著图通常包含很多视觉可见的噪音</mark></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[340,341]},"content":"<strong>无法确定</strong>这种<strong>噪音是否真实反映</strong>了模型在分类过程中的<strong>决策依据</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[341,342]},"content":"<img src=\"saliency_map.png\" alt=\"\" title=\"4种梯度反向传播解释方法解释效果对比\">","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[342,343]},"content":"<strong>Smilkov, <em>SmoothGard</em></strong>, <strong>平滑梯度的反向传播解释方法</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[343,344]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Smooth grad: Removing noise by adding noise</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Smooth grad: Removing noise by adding noise}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Smooth grad: Removing noise by adding noise</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[344,345]},"content":"<strong>向输入样本中引入噪声对相似的样本进行采样，对每个采样样本的决策显著图求平均</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[345,346]},"content":"<strong>解决</strong>了 <strong>Grad 等</strong>方法中存在的<strong>视觉噪音问题</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[346,347]},"content":"<strong><mark>以上方法无法量化特征对决策结果贡献程度</mark></strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[347,348]},"content":"<strong>Landecker, 贡献传播方法</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[348,349]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpreting individual classifications of hierarchical networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpreting individual classifications of hierarchical networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpreting individual classifications of hierarchical networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[349,350]},"content":"首先，<strong>加性模型计算 DNN 高层特征的贡献</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[350,351]},"content":"再用 <strong>BP 将高层的贡献传递到输入</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[351,352]},"content":"<strong>Bach, <em>Layer-wise relevance propagation, LRP</em></strong>, <strong>分层相关性传播方法</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[352,353]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[353,354]},"content":"计算<strong>单个像素</strong>对图像分类器<strong>预测结果</strong>的<strong>贡献</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[354,355]},"content":"<strong>假设分类器</strong>可以被<strong>分解为多个计算层</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[355,356]},"content":"<strong>每一层</strong>都可以被建模为<strong>一个多维向量</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[356,357]},"content":"并且<strong>该多维向量</strong>的<strong>每一维</strong>都<strong>对应一个相关性分值</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[357,358]},"content":"<strong>BP 将高层的相关性分值递归传播到输入层</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[358,359]},"content":"<strong>与 Grad 不同， LRP 方法不要求 DNN 神经元的激活是可微或平滑</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[359,360]},"content":"<strong>Shrikumar, <em>DeepLIFT</em></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[360,361]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Not just a black box: Learning important features through propagating activation differences</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Not just a black box: Learning important features through propagating activation differences}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Not just a black box: Learning important features through propagating activation differences</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[361,362]},"content":"在<strong>输入空间</strong>中<strong>定义参考点</strong>并<strong>参考神经元激活的变化按比例传播相关分数</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[362,363]},"content":"在<strong>不进行数值稳定性修正</strong>的情况下，<strong>原始 LRP</strong> 方法的<strong>输出</strong>结果<strong>等价于 Grad</strong> 方法所求<strong>显著图与输入之间的乘积</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[363,364]},"content":"<strong>Ding, <em>LRP</em> 应用于基于 AM 的 En-De</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[364,365]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Visualizing and understanding neural machine translation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Visualizing and understanding neural machine translation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Visualizing and understanding neural machine translation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[365,366]},"content":"<strong>由于 LRP 方法不要求 DNN 神经元的激活是可微或平滑</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[366,367]},"content":"<strong>度量</strong>神经网络中<strong>任意2个神经元</strong>之间关联程度的<strong>相关性</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[367,368]},"content":"有助于理解<strong>汉英翻译</strong>机制并分析错误","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[368,369]},"content":"<strong>Arras, LRP 引入 NLP</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[369,370]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>What is relevant in a text document? : An interpretable machine learning approach</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {What is relevant in a text document? : An interpretable machine learning approach}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">What is relevant in a text document? : An interpretable machine learning approach</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[370,371]},"content":"<strong>定性并定量证明 LRP</strong> 可用于<strong>文档级别的细粒度分析、跨文档的数据集级别的分析</strong>，以<strong>识别对分类决策重要的单词</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[371,372]},"content":"<strong>实现简单、计算效率高</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[372,373]},"content":"如果<strong>预测函数在输入附近变得平坦</strong>，那么<strong>预测函数相对于输入的梯度</strong>在该输入附近将变得<strong>很小</strong>，进而导致<strong>无法利用梯度信息定位样本的决策特征</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[373,374]},"content":"<strong>Integrated 一定程度上解决问题，但同时增加计算量，并且引入无法理解的噪音</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[374,375]},"content":"<strong>梯度信息只能定位重要特征，无法量化特征贡献度</strong>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[375,376]},"content":"<strong>特征反演 (Feature Inversion)</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[376,377]},"content":"利用 <strong>DNN 中间层特征表征，解释整体决策</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[377,378]},"content":"<strong>模型级 (model-level)</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[378,379]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Deep inside convolutional networks: Visualising image classification models and saliency maps</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Deep inside convolutional networks: Visualising image classification models and saliency maps}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Deep inside convolutional networks: Visualising image classification models and saliency maps</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[379,380]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Understanding deep image representations by inverting them</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Understanding deep image representations by inverting them}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Understanding deep image representations by inverting them</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[380,381]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Exploring neural networks with activation atlases</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Exploring neural networks with activation atlases}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Exploring neural networks with activation atlases</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[381,382]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Inverting visual representations with convolutional networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Inverting visual representations with convolutional networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Inverting visual representations with convolutional networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[382,383]},"content":"在从<strong>输入空间中</strong>寻找可以<strong>表示</strong> DNN 神经元<strong>所学到的抽象概念的解释原型</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[383,384]},"content":"<strong>可视化</strong>和<strong>理解 DNN 每一层特征表示</strong>的方式","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[384,385]},"content":"<strong>通常难以理解</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[385,386]},"content":"如何从输入样本中<strong>自动化提取</strong>用于模型决策的<strong>重要特征</strong>仍然<strong>困难</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[386,387]},"content":"<strong>实例级 (instance-level)</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[387,388]},"content":"<strong>输入样本的哪些特征</strong>被用于<strong>激活</strong> DNN 的神经元以<strong>做出特定的决策</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[388,389]},"content":"<strong>Du</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[389,390]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Towards explanation of DNN-based prediction with guided feature inversion</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Towards explanation of DNN-based prediction with guided feature inversion}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Towards explanation of DNN-based prediction with guided feature inversion</span></span></span></span></span>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[390,391]},"content":"执行<strong>导向特征反演过程中加入类别依赖约束</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[391,392]},"content":"<img src=\"guided_feature_inversion_method.png\" alt=\"\" title=\"导向特征反演方法解释示例\">","children":[]}]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[392,393]},"content":"<strong>类激活映射 <em>(Class Activation Mapping, CAM)</em></strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[393,394]},"content":"<strong>CNN 不同层次</strong>的<strong>卷积单元</strong>包含<strong>大量</strong>的<strong>位置信息</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[394,395]},"content":"<strong>传统 CNN</strong> 模型通常在<strong>卷积和池化之后采用全连接层</strong>对卷积层提取的特征图进行组合用于最终决策，因而<strong>导致</strong>网络的<strong>定位能力丧失</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[395,396]},"content":"<strong>Zhou, <em>class activation mapping (CAM)</em>, 类激活映射</strong>, <strong>平均池化代替全连接</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[396,397]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning deep features for discriminative localization</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning deep features for discriminative localization}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning deep features for discriminative localization</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[397,398]},"content":"用<strong>全局平均池化(global average pooling)代替</strong>传统 CNN 中<strong>除softmax以外的所有全连接层</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[398,399]},"content":"<strong>全局平均池化输出 CNN 最后一个卷积层每个单元的特征图的空间平均值</strong>","children":[{"type":"list_item","depth":11,"payload":{"lines":[399,400]},"content":"对<strong>空间平均值加权求和得到</strong> CNN 的最终<strong>决策结果</strong>","children":[]},{"type":"list_item","depth":11,"payload":{"lines":[400,401]},"content":"<strong>计算加权和得到类激活图</strong>，通过<strong>热力图形式可视化</strong>","children":[]}]}]},{"type":"list_item","depth":9,"payload":{"lines":[401,402]},"content":"<strong>作为正则器防止过拟合</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[402,403]},"content":"<strong>保留定位能力保留在网络最后一层</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[403,404]},"content":"<strong>需要修改网络结构并重新训练模型</strong>，因而在实际应用中<strong>并不实用</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[404,405]},"content":"<strong>Selvaraju, <em>Grad-CAM</em></strong> , <strong>梯度信息结合特征映射的梯度加权类激活映射方法, 特征图局部梯度求平均后作为特征图权重</strong>, <strong>Guided Grad-CAM</strong>, <strong>导向梯度加权类激活映射方法</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[405,406]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Grad-CAM: Visual explanations from deep networks via gradient-based localization</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Grad-CAM: Visual explanations from deep networks via gradient-based localization}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Grad-CAM: Visual explanations from deep networks via gradient-based localization</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[406,407]},"content":"<strong><em>Grad-CAM</em></strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[407,408]},"content":"<strong>计算目标类别相对于最后一个卷积层中每一个特征图的梯度</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[408,409]},"content":"<strong>对梯度进行全局平均池化</strong>，以<strong>获得每个特征图的重要性权重</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[409,410]},"content":"<strong>基于重要性权重计算特征图的加权激活，获得</strong>一个<strong>粗粒度的梯度加权类激活图，定位输入样本中具有类判别性的重要区域</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[410,411]},"content":"对于<strong>全连接神经网络</strong>，<strong>Grad-CAM 退化为 CAM</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[411,412]},"content":"<strong>相比CAM, Grad-CAM 无需修改网络架构或重训练模型</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[412,413]},"content":"<strong>虽然 Grad-CAM 具有良好</strong>的<strong>类别判别能力</strong>并能<strong>很好地定位相关图像区域，但缺乏如 DeconvNet 和 GuidedBP 等像素级别梯度可视化解释方法显示细粒度特征重要性的能力</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[413,414]},"content":"<strong><em>Guided Grad-CAM</em></strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[414,415]},"content":"<strong>为获得更细粒度的特征重要性，结合 Grad-CAM 和 GuidedBP , 提出 Guided Grad-CAM</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[415,416]},"content":"<strong>双线性插值将梯度加权类激活图上采样到输入图片分辨率大小</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[416,417]},"content":"<strong>点乘 GuidedBP 的输出，得到细粒度的类判别性特征定位图</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[417,418]},"content":"<strong>Guided Grad-CAM 效果优于 GuidedBP 和 Grad-CAM</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[418,419]},"content":"<img src=\"Grad_CAM_and_Guided_Grad_CAM.png\" alt=\"\" title=\"Grad-CAM与Guided Grad-CAM方法解释结果可视化\">","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[419,420]},"content":"<strong>Chattopadhyay, <em>Grad-CAM++</em></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[420,421]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Grad-CAM++: generalized gradient-based visual explanations for deep convolutional networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Grad-CAM++: generalized gradient-based visual explanations for deep convolutional networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Grad-CAM++: generalized gradient-based visual explanations for deep convolutional networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[421,422]},"content":"<strong>梯度图上元素贡献有差异，增加权重二次加权</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[422,423]},"content":"<img src=\"CAM_mechanism.png\" alt=\"\" title=\"类激活映射机制\">","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[423,424]},"content":"<strong>Wang, <em>Score-weighted CAM</em></strong>, <strong>不依赖梯度的权重表示法</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[424,425]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Score-CAM: score-weighted visual explanations for convolutional neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Score-CAM: score-weighted visual explanations for convolutional neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Score-CAM: score-weighted visual explanations for convolutional neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[425,426]},"content":"<strong>Grad-CAM易于找到错误置信度的样本，即部分权重较低的特征图获得了很高的置信度，而且局部的梯度存在饱和问题，受噪声影响很大</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[426,427]},"content":"<strong><em>CIC(Channel-wise Increase of Confidence)</em></strong> <strong>置信度提升</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[427,428]},"content":"<strong>特征图上采样后，与原图像进行点乘，用处理后的图像响应与原图像响应之差表示该特征图的重要性</strong>","children":[{"type":"list_item","depth":11,"payload":{"lines":[428,429]},"content":"<img src=\"CIC.png\" alt=\"\" title=\"置信度提升\">","children":[]}]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[429,430]},"content":"<strong>Desai, <em>Ablation-CAM</em></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[430,431]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Ablation-CAM: visual explanations for deep convolutional network via gradient-free localization</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Ablation-CAM: visual explanations for deep convolutional network via gradient-free localization}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Ablation-CAM: visual explanations for deep convolutional network via gradient-free localization</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[431,432]},"content":"<strong>Ablation分析</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[432,433]},"content":"<strong>遍历地将每层特征图置0再进行网络前向获取目标类别得分，把该值与原始得分的相对大小作为权重</strong>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[433,434]},"content":"<strong>实现简单、计算效率高、易于理解</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[434,435]},"content":"<strong>CAM 只适合 CNN ，难扩展到全连接神经网络(FCN)和 RNN 等</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[435,436]},"content":"<strong>基于类激活映射的可解释性方法通过对特征图分配不同的权重来生成类激活图，实现了区域级的可视化，可以进一步区别分类；但它们关于权重的分配缺乏对应的理论基础</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[436,437]},"content":"<strong><em>Guided Grad-CAM</em> 由于引入导向反向传播方法</strong>，同样存在<strong>负梯度归零</strong>导致<strong>无法定位与模型决策结果呈负相关的样本特征</strong>的局限性","children":[{"type":"list_item","depth":9,"payload":{"lines":[437,438]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning important features through propagating activation differences</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning important features through propagating activation differences}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning important features through propagating activation differences</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[438,439]},"content":"<img src=\"CAM.png\" alt=\"\" title=\"基于类激活映射的可解释性方法\">","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[439,440]},"content":"<strong>抽象解释</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[440,441]},"content":"<strong>Gehr,</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">A</mi><msup><mi mathvariant=\"bold-italic\">I</mi><mn mathvariant=\"bold\">2</mn></msup></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{AI^2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">A</span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.07778em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></span>, <strong>可扩展的、可用于验证和分析 DNN 安全性和鲁棒性的抽象解释系统</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[441,442]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Ai2: Safety and robustness certification of neural networks with abstract interpretation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Ai2: Safety and robustness certification of neural networks with abstract interpretation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Ai2: Safety and robustness certification of neural networks with abstract interpretation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[442,443]},"content":"<strong>DNN</strong> 的<strong>每一层</strong>处理的是<strong>具体数值</strong>，<strong>抽象元素无法在网络中传播</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[443,444]},"content":"<strong>抽象转换器(abstract transformer)将 DNN 每一层转换为对应的抽象层</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[444,445]},"content":"基于<strong>抽象元素过近似(over-approximation)</strong>，<strong>原神经网络每一层</strong>的处理函数以<strong>捕获其真实行为</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[445,446]},"content":"<strong>基于抽象转换器返回的抽象结果</strong>，<strong>分析并验证</strong>神经网络的<strong>鲁棒性和安全性</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[446,447]},"content":"<strong>不用真正运行 DNN</strong> 模型即可验证 DNN 的某些特定属性，因而<strong>计算效率高</strong>，<strong>可扩展到大规模、更复杂的 DNN 网络</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[447,448]},"content":"但由于采用了<strong>过近似处理</strong>，尽管 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">A</mi><msup><mi mathvariant=\"bold-italic\">I</mi><mn mathvariant=\"bold\">2</mn></msup></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{AI^2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">A</span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.07778em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></span> 能提供可靠的解释但<strong>无法保证解释的准确性</strong>","children":[]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[448,449]},"content":"<strong>准确一致解释</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[449,450]},"content":"<strong>现有局部解释方法包括抽象解释都很难保证解释结果的准确性和一致性</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[450,451]},"content":"<strong>Chu, <em>OpenBox</em></strong>, <strong>准确一致的解释方法 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[451,452]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Exact and consistent interpretation for piecewise linear neural networks: A closed form solution</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Exact and consistent interpretation for piecewise linear neural networks: A closed form solution}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Exact and consistent interpretation for piecewise linear neural networks: A closed form solution</span></span></span></span></span>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[452,453]},"content":"<strong>可为分段线性神经网络(PLNN)家族模型提供精确一致性解释</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[453,454]},"content":"<strong>PLNN 在数学上等价于一系列局部线性分类器</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[454,455]},"content":"<strong>每一个线性分类器负责分类输入空间中的一组样本</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[455,456]},"content":"<strong>线性解释模型</strong>针对每一个输入的决策结果<strong>与待解释 PLNN 的决策结果完全一致</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[456,457]},"content":"<strong>解决</strong>了模型的<strong>可解释性与准确性之间的权衡难题</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[457,458]},"content":"<strong>只适用于线性神经网络模型，拓展性不强</strong>","children":[]}]}]}]}]}]},{"type":"list_item","depth":4,"payload":{"lines":[458,459]},"content":"<strong>隐层可解释化</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[459,460]},"content":"<strong>Bau, <em>Network Dissection</em>. 网络切割</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[460,461]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Network dissection: quantifying interpretability of deep visual representations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Network dissection: quantifying interpretability of deep visual representations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Network dissection: quantifying interpretability of deep visual representations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[461,462]},"content":"<strong>自动标定带有语义的神经元，计算隐层-概念对匹配程度，量化分析不同CNN中神经元语义特征</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[462,463]},"content":"<strong><mark>但是单个神经元不是不包含语义吗？语义存在于整层内，而不是单个神经元？</mark></strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[463,464]},"content":"<strong>Zhang, 解释图(Explanatory Graph)可视化滤波器</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[464,465]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpreting CNN knowledge via an explanatory graph</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpreting CNN knowledge via an explanatory graph}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpreting CNN knowledge via an explanatory graph</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[465,466]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Extraction of an explanatory graph to interpret a CNN</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Extraction of an explanatory graph to interpret a CNN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Extraction of an explanatory graph to interpret a CNN</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[466,467]},"content":"<strong>解释图(Explanatory Graph)</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[467,468]},"content":"<strong>每个节点严格表示某个子模式</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[468,469]},"content":"<strong>每个边表示不同模式的同时激活关系和空间关系</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[469,470]},"content":"<strong>将高层卷积层的混乱的知识表达拆分开，具备更好的可迁移性</strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[470,471]},"content":"<strong>Aubry, 用PCA可视化隐层的激活</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[471,472]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Understanding deep features with computer-generated imagery</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Understanding deep features with computer-generated imagery}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Understanding deep features with computer-generated imagery</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[472,473]},"content":"<strong>Rauber, <em>t-SNE(t-distributed Stochastic Neighbor Embedding)</em> t-分布随机近邻嵌入，降维高维数据</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[473,474]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Visualizing the hidden activity of artificial neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Visualizing the hidden activity of artificial neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Visualizing the hidden activity of artificial neural networks</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[474,475]},"content":"<strong>有时隐层并没有特定含义，主观性较强</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[475,476]},"content":"<strong>基于敏感性分析的可解释性</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[476,477]},"content":"<strong>敏感性分析 <em>Sensitivity Analysis</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[477,478]},"content":"<strong>变量敏感性</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[478,479]},"content":"<strong>利用不同的隐层激活函数的偏导数评估输入变量对输出的影响</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[479,480]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mn mathvariant=\"bold\">20</mn></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{20}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">20</span></span></span></span></span></span>","children":[{"type":"list_item","depth":9,"payload":{"lines":[480,481]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Use of some sensitivity criteria for choosing networks with good generalization ability</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Use of some sensitivity criteria for choosing networks with good generalization ability}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Use of some sensitivity criteria for choosing networks with good generalization ability</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[481,482]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mn mathvariant=\"bold\">21</mn></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{21}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">21</span></span></span></span></span></span>","children":[{"type":"list_item","depth":9,"payload":{"lines":[482,483]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Feature selection using a multilayer perceptron</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Feature selection using a multilayer perceptron}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Feature selection using a multilayer perceptron</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[483,484]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mn mathvariant=\"bold\">22</mn></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{22}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">22</span></span></span></span></span></span>","children":[{"type":"list_item","depth":9,"payload":{"lines":[484,485]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>New indices for characterizing spatial models of ore deposits by the use of a sensitivity vector and an influence factor</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {New indices for characterizing spatial models of ore deposits by the use of a sensitivity vector and an influence factor}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">New indices for characterizing spatial models of ore deposits by the use of a sensitivity vector and an influence factor</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":8,"payload":{"lines":[485,486]},"content":"<img src=\"Sensitivity_Analysis.png\" alt=\"\" title=\"敏感性分析\">","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[486,487]},"content":"<strong>Dombi, <em>MIV (Mean Impact Value)</em></strong> <strong>平均影响值</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[487,488]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Prediction of rib fracture injury outcome by an artificial neural network</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Prediction of rib fracture injury outcome by an artificial neural network}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Prediction of rib fracture injury outcome by an artificial neural network</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[488,489]},"content":"<strong>直接变动各个自变量的特征值，并按观测样本数进行平均，得到对应的输出的变化值，其绝对值大小表示变量的重要性程度</strong>","children":[]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[489,490]},"content":"<strong>样本敏感性</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[490,491]},"content":"<strong>Koh</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[491,492]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Understanding black-box predictions via influence functions</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Understanding black-box predictions via influence functions}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Understanding black-box predictions via influence functions</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[492,493]},"content":"<strong>利用影响力函数，刻画了对训练样本施加轻微扰动后特定测试样本损失函数的变化，来理解模型的预测效果</strong>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[493,494]},"content":"<strong><em>LIME (Local Interpretable Model-sgnostic Explanation)</em></strong>, <strong>一种与模型无关的局部近似</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[494,495]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>“Why should I trust you？”: explaining the predictions of any classifier</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {“Why should I trust you？”: explaining the predictions of any classifier}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">“Why should I trust you</span><span class=\"mord cjk_fallback\" style=\"color:green;\">？</span><span class=\"mord\" style=\"color:green;\">”: explaining the predictions of any classifier</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[495,496]},"content":"<strong>在关注的样本点附近进行轻微扰动后，探测模型的输出发生的变化，根据这种变化在兴趣点附近拟合出一个可解释的简单模型（如线性模型、决策树）</strong>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[496,497]},"content":"<strong>Hui, 基于负特征和多数贡献的分解规则</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[497,498]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Deep interpretation with sign separated and contribution recognized decomposition</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Deep interpretation with sign separated and contribution recognized decomposition}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Deep interpretation with sign separated and contribution recognized decomposition</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[498,499]},"content":"认为<strong>负贡献可能不等于负相关性，需要在关联分解中分别处理正贡献和负贡献</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[499,500]},"content":"<strong>同时提高</strong>网络中<strong>各属性的贡献对</strong>最终网络<strong>决策的敏感性和相关性</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[500,501]},"content":"<strong>良好的可解释结果</strong>","children":[]}]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[501,502]},"content":"<strong>把解释性归因于输入特征或者样本，适合解释个体输入，但通常很难从中获得对网络的总体理解</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[502,503]},"content":"<strong><mark>个体输入具有代表性？</mark></strong>","children":[]}]}]}]},{"type":"list_item","depth":4,"payload":{"lines":[503,504]},"content":"<strong>基于鲁棒性扰动测试的可解释性</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[504,505]},"content":"<strong>Gowal, <em>IBP (Interval Bound Propagation)</em></strong>, <strong>区间定向传播</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[505,506]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Scalable verified training for provably robust image classification</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Scalable verified training for provably robust image classification}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Scalable verified training for provably robust image classification</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[506,507]},"content":"<strong>省略神经网络的最后一层线性层，提高了对单模型结构的验证精度</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[507,508]},"content":"<strong>并且，由于IBP的计算成本仅相当于网络的两次前向传递，可以执行更广泛的超参数搜索，进而训练大型的神经网络</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[508,509]},"content":"<strong>Pezeshkpour, 对链路预测模型的对抗性修改</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[509,510]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Investigating robustness and interpretability of link prediction via adversarial modifications</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Investigating robustness and interpretability of link prediction via adversarial modifications}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Investigating robustness and interpretability of link prediction via adversarial modifications</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[510,511]},"content":"<strong><em>CRIAGE (Completion Robustness and Interpretability via Adversarial Graph Edits)</em></strong>, <strong>对抗性图编辑完成鲁棒性和可解释性</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[511,512]},"content":"<strong>通过对知识图谱的修改</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[512,513]},"content":"<strong>利用对图的删除，可以识别出对预测链接最有影响的事实来研究可解释性</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[513,514]},"content":"<strong>利用对图的添加，评估模型的鲁棒性</strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[514,515]},"content":"<strong>Moshkovitz, <em>BBM-RS, (learning Risk Scores relying on Boost-By-Majority)</em></strong>, <strong>基于决策树的风险评分算法</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[515,516]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Connecting interpretability and robustness in decision trees through separation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Connecting interpretability and robustness in decision trees through separation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Connecting interpretability and robustness in decision trees through separation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[516,517]},"content":"<strong>真实数据是接近线性可分</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[517,518]},"content":"<strong>同时使模型具有可解释性和鲁棒性</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[518,519]},"content":"<strong>利用本身就具有可解释性的风险评分模型，保证生成的分类器在具有较高的分类精度的同时，具有鲁棒性和可解释性</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[519,520]},"content":"<strong>Koo，探究了第一层的激活函数对模型的可解释性的影响</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[520,521]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Improving representations of genomic sequence motifs in convolutional networks with exponential activations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Improving representations of genomic sequence motifs in convolutional networks with exponential activations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Improving representations of genomic sequence motifs in convolutional networks with exponential activations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[521,522]},"content":"<strong>发现指数激活函数可以产生鲁棒的表示，而与网络深度无关。</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[522,523]},"content":"<strong>通过设置 CNN 第一层的激活函数为指数激活</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[523,524]},"content":"<strong>可以在激活前抑制背景，只传播有辨识性的信号</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[524,525]},"content":"<strong>从而使第一层滤波器具有更好的可解释性，同时显著提高模型的鲁棒性</strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[525,526]},"content":"<strong>Chen, <em>DDNMF (Deep Denoising Non-negative Matrix Factorization)</em></strong> <strong>具有非负约束的深度矩阵分解</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[526,527]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A deep non-negative matrix factorization model for big data representation learning</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A deep non-negative matrix factorization model for big data representation learning}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A deep non-negative matrix factorization model for big data representation learning</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[527,528]},"content":"<strong>用于学习数据的鲁棒可解释的深度学习表示</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[528,529]},"content":"<strong>包含教师网络和学生网络两个部分，每个网络都包括一个编码器和解码器</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[529,530]},"content":"<strong>学生网络</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[530,531]},"content":"<strong>编码器和解码器间包括一个非负矩阵分解（Non-negative Matrix Factorization，NMF）模块</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[531,532]},"content":"<strong>接受并分解编码后的表示，再通过矩阵乘法恢复表示，以进行后续的解码，为模型带来可解释性</strong>","children":[]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[532,533]},"content":"<strong>教师网络</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[533,534]},"content":"<strong>抑制输入数据中的噪声</strong>","children":[]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[534,535]},"content":"<strong>通过定义一个可解释的损失，确保知识从教师网络转移到学生网络，增强表示的鲁棒性</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[535,536]},"content":"<strong>通过对精心设计过的新输入对模型预测的影响程度进行解释，为模型提供了安全保证，但这类举例的方法解释力最低</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[536,537]},"content":"<strong>基于频率原理的可解释性 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[537,538]},"content":"<strong>2018, Xu, F-principle (Frequency principle)</strong>, <strong>频率原理 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[538,539]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Training behavior of deep neural network in frequency domain</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Training behavior of deep neural network in frequency domain}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Training behavior of deep neural network in frequency domain</span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[539,540]},"content":"<strong>在训练过程中，DNN 会先捕获低频分量，同时保持较小的高频分量，之后再缓慢地捕获高频分量</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[540,541]},"content":"<strong>因此，对低频占优的目标函数及对象，DNN 往往具有较好的泛化能力；而对于高频占优对象，DNN 则具有较差的表现</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[541,542]},"content":"<strong>解释对低频占优的目标函数为什么提前终止训练能防止过拟合</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[542,543]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Frequency principle: Fourier analysis sheds light on deep neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Frequency principle: Fourier analysis sheds light on deep neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Frequency principle: Fourier analysis sheds light on deep neural networks</span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[543,544]},"content":"<strong>从傅里叶分析的角度，解释了训练好的 DNN 在拟合奇偶函数时泛化能力差的原因</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[544,545]},"content":"<strong>理论上证明了频率原理是由于激活函数的平滑性导致的</strong>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[545,546]},"content":"<strong>并将DNN低频占优的原则和雅可比方法先收敛高频的特性相结合，加快求解泊松方程，为求解微分方程的数值解提供了新思路</strong>","children":[]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[546,547]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Deep frequency principle towards understanding why deeper learning is faster</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Deep frequency principle towards understanding why deeper learning is faster}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Deep frequency principle towards understanding why deeper learning is faster</span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[547,548]},"content":"<strong>解释了为什么更深层的前馈神经网络训练更快</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[548,549]},"content":"<strong>一个从隐层到输出层的子网络，其等效目标函数由隐层上一层的输出和真实标签构成</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[549,550]},"content":"<strong>文中将整个神经网络分成 pre-condition 和 learning 两个部分，并着重分析了 learning 部分的表现</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[550,551]},"content":"<strong>发现更深层的神经网络的有效目标函数在训练过程中会更趋近于低频，再基于低频先收敛的 F-principle，为更深的神经网络收敛更快提供了一种可能的解释</strong>","children":[]}]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[551,552]},"content":"<strong>Zhang, <em>LFP (Linear Frequency Principle)</em></strong>, <strong>线性频率原理 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[552,553]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A linear frequency principle model to understand the absence of overfitting in neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A linear frequency principle model to understand the absence of overfitting in neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A linear frequency principle model to understand the absence of overfitting in neural networks</span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[553,554]},"content":"<strong>用一个简单的微分方程刻画了神经网络训练过程中的关键特征</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[554,555]},"content":"<strong>只考虑网络参数的一些宏观统计量，忽略了单个参数的具体行为</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[555,556]},"content":"<strong><mark>进而解释了 DNN 在参数极多的情况下依然强大的泛化能力的原因</mark></strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[556,557]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Explicitizing an implicit bias of the frequency principle in two-layer neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Explicitizing an implicit bias of the frequency principle in two-layer neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Explicitizing an implicit bias of the frequency principle in two-layer neural networks</span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[557,558]},"content":"<strong>将频率原理的内隐偏差作为两层神经网络的显式惩罚加以明确</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[558,559]},"content":"<strong>准确预测了大宽度的双层 ReLU 神经网络的学习结果</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[559,560]},"content":"<strong>给出了泛化误差边界的先验估计</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[560,561]},"content":"<strong><mark>定量理解一般神经网络的学习和泛化</mark></strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[561,562]},"content":"<strong>Luo，傅里叶分析的理论框架</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[562,563]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Theory of the frequency principle for general deep neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Theory of the frequency principle for general deep neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Theory of the frequency principle for general deep neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[563,564]},"content":"<strong>发现 DNN 的正则性转化为损失函数在频域中的衰减率</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[564,565]},"content":"<strong>验证了频率原理的通用性</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[565,566]},"content":"<strong>Wang, 探究了卷积核的平滑性和模型鲁棒性之间的关系</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[566,567]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>High-frequency component helps explain the generalization of convolutional neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {High-frequency component helps explain the generalization of convolutional neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">High-frequency component helps explain the generalization of convolutional neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[567,568]},"content":"<strong>CNN 可以利用人类无法感知的图像高频信号</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[568,569]},"content":"<strong>提出了帮助 CNN 提高对抗鲁棒性的不需要训练或者微调模型的防御方法</strong>","children":[]}]}]},{"type":"list_item","depth":4,"payload":{"lines":[569,570]},"content":"<strong>基于信息论的可解释性 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[570,571]},"content":"<strong>2000, Tishby, 信息瓶颈理论 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[571,572]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>The information bottleneck method</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {The information bottleneck method}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">The information bottleneck method</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[572,573]},"content":"<strong>将 x 中所有与 y 相关的信息捕获，就可以任意压缩 x 而不丢失预测 y 的能力，即为 x 寻找一个能最大限度地保留 y 信息的短代码</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[573,574]},"content":"<strong>2015, Tishby, 信息平面</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[574,575]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Deep learning and the information bottleneck principle</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Deep learning and the information bottleneck principle}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Deep learning and the information bottleneck principle</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[575,576]},"content":"<strong>通过层间和输入输出变量之间的互信息来量化网络结构，输入层相对于输出层的相关压缩，层状网络的层次化表示对应于沿信息曲线的结构相变</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[576,577]},"content":"<strong>Schwartz-Ziv, 信息平面DNN可视化</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[577,578]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Opening the black box of deep neural networks via information</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Opening the black box of deep neural networks via information}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Opening the black box of deep neural networks via information</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[578,579]},"content":"<img src=\"information_1.png\" alt=\"\" title=\"信息平面\">","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[579,580]},"content":"<img src=\"information_2.png\" alt=\"\" title=\"信息平面\">","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[580,581]},"content":"<strong>Achille, 参数信息量</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[581,582]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Emergence of invariance and disentanglement in deep representations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Emergence of invariance and disentanglement in deep representations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Emergence of invariance and disentanglement in deep representations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[582,583]},"content":"<strong>参数数量不能真正衡量神经网络的复杂程度，真正起作用的是网络参数中所含参数的信息量</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[583,584]},"content":"<strong>权重中的信息来衡量学习模型的复杂性</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[584,585]},"content":"<strong>网络表示学习成分的不变性和独立性是由权值中的信息限定的</strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[585,586]},"content":"<strong>Pimentel, 探针作为互信息的估计</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[586,587]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Information theoretic probing for linguistic structure </mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Information theoretic probing for linguistic structure }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Information theoretic probing for linguistic structure </span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[587,588]},"content":"<strong>控制函数评估探针的有效性并进行了相应解释</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[588,589]},"content":"<strong>Bang, <em>VIBI (Variational Information Bottleneck for Interpretation)</em></strong>, <strong>变分信息瓶颈 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[589,590]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Explaining a black-box by using a deep variational bottleneck approach</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Explaining a black-box by using a deep variational bottleneck approach}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Explaining a black-box by using a deep variational bottleneck approach</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[590,591]},"content":"<strong>对于每个实例，解释器返回一个概率，即是否将一个词、短语或句子（NLP）或者一组像素（CV）等特征块作为解释选择，再将选定的特征块作为信息瓶颈来最大限度地压缩输入和输出之间的信息</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[591,592]},"content":"<strong>系统无关，可解释任何黑箱模型</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[592,593]},"content":"<strong>更多信息的解释，但泛化到不同网络结构时效果较差</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[593,594]},"content":"<strong>基于可解释模块的可解释性 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[594,595]},"content":"<strong>2017, Sabour, <em>Capsule</em></strong>, <strong>胶囊网络</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[595,596]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Dynamic routing between capsules</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Dynamic routing between capsules}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Dynamic routing between capsules</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[596,597]},"content":"<strong>胶囊</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[597,598]},"content":"<strong>新型神经元</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[598,599]},"content":"<strong>输出: 活动向量</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[599,600]},"content":"<strong>范数: 置信度</strong>","children":[]},{"type":"list_item","depth":9,"payload":{"lines":[600,601]},"content":"<strong>方向: 实例化参数</strong>","children":[]}]}]},{"type":"list_item","depth":7,"payload":{"lines":[601,602]},"content":"<strong>输入向量</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">v</mi><mn mathvariant=\"bold\">1</mn></msub><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold-italic\">v</mi><mn mathvariant=\"bold\">2</mn></msub></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{v_1, v_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>先仿射变换得到</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">u</mi><mn mathvariant=\"bold\">1</mn></msub><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold-italic\">u</mi><mn mathvariant=\"bold\">2</mn></msub></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{u_1, u_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span><strong>，再加权和</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">s</mi><mo>=</mo><msub><mi mathvariant=\"bold-italic\">c</mi><mn mathvariant=\"bold\">1</mn></msub><msub><mi mathvariant=\"bold-italic\">u</mi><mn mathvariant=\"bold\">1</mn></msub><mo mathvariant=\"bold-italic\">+</mo><msub><mi mathvariant=\"bold-italic\">c</mi><mn mathvariant=\"bold\">2</mn></msub><msub><mi mathvariant=\"bold-italic\">u</mi><mn mathvariant=\"bold\">2</mn></msub></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{s=c_1u_1 + c_2u_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7833em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">s</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord boldsymbol\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin mathbf\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord boldsymbol\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span><strong>，再通过挤压方程(squashing function) 得到输出向量</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">v</mi><mo>=</mo><mfrac><mrow><mo>∥</mo><mi mathvariant=\"bold-italic\">s</mi><msup><mo>∥</mo><mn mathvariant=\"bold\">2</mn></msup></mrow><mrow><mn mathvariant=\"bold\">1</mn><mo mathvariant=\"bold-italic\">+</mo><mo>∥</mo><mi mathvariant=\"bold-italic\">s</mi><msup><mo>∥</mo><mn mathvariant=\"bold\">2</mn></msup></mrow></mfrac><mfrac><mi mathvariant=\"bold-italic\">s</mi><mrow><mo>∥</mo><mi mathvariant=\"bold-italic\">s</mi><mo>∥</mo></mrow></mfrac></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{v=\\frac{\\parallel s\\parallel^2}{1+\\parallel s\\parallel^2}\\frac s{\\parallel s\\parallel}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.6289em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.03704em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1089em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">1</span><span class=\"mord mathbf mtight\">+</span><span class=\"mrel mathbf mtight\">∥</span><span class=\"mord boldsymbol mtight\">s</span><span class=\"mrel mtight\"><span class=\"mrel mathbf mtight\">∥</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7463em;\"><span style=\"top:-2.786em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mathbf mtight\">∥</span><span class=\"mord boldsymbol mtight\">s</span><span class=\"mrel mtight\"><span class=\"mrel mathbf mtight\">∥</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913em;\"><span style=\"top:-2.931em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7051em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mathbf mtight\">∥</span><span class=\"mord boldsymbol mtight\">s</span><span class=\"mrel mathbf mtight\">∥</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[602,603]},"content":"<strong>加权和系数</strong><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><msub><mi mathvariant=\"bold-italic\">c</mi><mn mathvariant=\"bold\">1</mn></msub><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold-italic\">c</mi><mn mathvariant=\"bold\">2</mn></msub></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{c_1, c_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span><strong>通过 <em>Dynamic Routing</em> 动态路得到</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[603,604]},"content":"<strong>能够编码特定语义概念，知道每个胶囊的作用</strong>","children":[]}]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[604,605]},"content":"<strong>2017, Wu, <em>R-CNN (Region-CNN)</em></strong>, <strong>可解释的基于候选区域的CNN</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[605,606]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Towards interpretable R-CNN by unfolding latent structures</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Towards interpretable R-CNN by unfolding latent structures}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Towards interpretable R-CNN by unfolding latent structures</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[606,607]},"content":"<strong><em>region proposal</em>, 目标检测的区域建议</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[607,608]},"content":"<strong><em>RoI (Region of Interest)</em></strong>, <strong>兴趣区域</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[608,609]},"content":"<strong>基于RoIPooling算子对边界框建议进行分类和回归</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[609,610]},"content":"<strong>为了实现弱监督自动化学习，本文用AOG (directed acyclic And-Or-Graph), 有向无环与或图解析算子代替RoIPooling</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[610,611]},"content":"<strong>在检测过程中，每个包围框都可以由实时从 AOG派生的最佳解析树进行解释</strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[611,612]},"content":"<strong>2016, Chen, <em>Info-GAN (Information-maximizing Generative Adversarial Network)</em></strong>, <strong>基于信息最大化的生成对抗网络</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[612,613]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>InfoGAN: interpretable representation learning by information maximizing generative adversarial nets</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {InfoGAN: interpretable representation learning by information maximizing generative adversarial nets}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">InfoGAN: interpretable representation learning by information maximizing generative adversarial nets</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[613,614]},"content":"<strong>完全无监督的方式学习解离化表征的生成对抗网络的信息理论扩展 <mark>类似反证法 ？</mark></strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[614,615]},"content":"<strong>改进GAN</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[615,616]},"content":"<strong>输入噪声向量分为两部分，最大化可以得到的互信息</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[616,617]},"content":"<strong>随机噪声</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">Z</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{Z}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.06979em;\">Z</span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[617,618]},"content":"<strong>隐向量</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">C</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{C}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.06979em;\">C</span></span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":7,"payload":{"lines":[618,619]},"content":"<strong>要求生成数据和隐向量</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">C</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{C}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.06979em;\">C</span></span></span></span></span></span> <strong>之间有尽可能多的互信息</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[619,620]},"content":"<img src=\"Info_GAN.png\" alt=\"\" title=\"Info-GAN\">","children":[]}]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[620,621]},"content":"<strong>Gu, <em>GraCapsNets (Graph Capsule Networks)</em></strong>, <strong>可解释图胶囊网络</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[621,622]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable graph capsule networks for object recognition</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable graph capsule networks for object recognition}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable graph capsule networks for object recognition</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[622,623]},"content":"<strong>基于多头注意力的图池化，替换基本路由</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[623,624]},"content":"<strong>容易解释分类决策</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[624,625]},"content":"<strong>可以更好地针对目标任务进行解释，但需要网络和解释模块之间的兼容性</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[625,626]},"content":"<strong>基于优化方法的可解释性</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[626,627]},"content":"<strong>Daubechies, <em>ISTA (Iterative Shrinkage Thresholding Algorithm)</em></strong>, <strong>迭代收缩阈值算法 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[627,628]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>An iterative thresholding algorithm for linear inverse problems with a sparsity constraint</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {An iterative thresholding algorithm for linear inverse problems with a sparsity constraint}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">An iterative thresholding algorithm for linear inverse problems with a sparsity constraint</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[628,629]},"content":"<strong>求解稀疏编码的优化方法</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[629,630]},"content":"<strong>Zhou, <em>SC2Net (Sparse Coding to Network)</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[630,631]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>SC2Net: sparse LSTMs for sparse coding</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {SC2Net: sparse LSTMs for sparse coding}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">SC2Net: sparse LSTMs for sparse coding</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[631,632]},"content":"<strong>引入新的自适应动量，转化为 RNN , 将对 L1 范数的优化方法与 LSTM 结合起来</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[632,633]},"content":"<strong>考虑了优化变量更新时每个维度之间的不同和历史信息</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[633,634]},"content":"<strong>Gregor, <em>LISTA (Learned ISTA)</em></strong>, <strong>学习的迭代收缩阈值算法</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[634,635]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning fast approximations of sparse coding</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning fast approximations of sparse coding}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning fast approximations of sparse coding</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[635,636]},"content":"<strong>将 ISTA 展开到循环神经网络中</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[636,637]},"content":"<strong>Liu, <em>ALISTA (Analytic LISTA)</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[637,638]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>ALISTA: analytic weights are as good as learned weights in LISTA</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {ALISTA: analytic weights are as good as learned weights in LISTA}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">ALISTA: analytic weights are as good as learned weights in LISTA</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[638,639]},"content":"<strong>只留下步长大小和阈值参数的数据驱动学习，大幅简化了训练</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[639,640]},"content":"<strong>2015, Zhang, <em>CRF (Conditional Random Field)</em></strong>, <strong>结合CNN与条件随机场概率图</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[640,641]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Conditional random fields as recurrent neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Conditional random fields as recurrent neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Conditional random fields as recurrent neural networks</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[641,642]},"content":"<strong>条件随机场的求解表示成 RNN 的相关运算</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[642,643]},"content":"<strong><em>CRF-RNN</em></strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[643,644]},"content":"<strong>学习CRF参数</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[644,645]},"content":"<strong>反向传播、端到端</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[645,646]},"content":"<strong>图像语义分割上实现突破</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[646,647]},"content":"<strong>Wang, 深度L0编码器</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[647,648]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning deep encoders</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning deep encoders}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning deep encoders</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[648,649]},"content":"<strong>优化对L0范数的稀疏逼近</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[649,650]},"content":"<strong>基于稳健迭代算法，引入新的神经元和池化函数，构建前向式神经网络</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[650,651]},"content":"<strong>Zuo, 实现稀疏编码的回复式神经网络</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[651,652]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning iteration-wise generalized shrinkage-thresholding operators for blind deconvolution</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning iteration-wise generalized shrinkage-thresholding operators for blind deconvolution}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning iteration-wise generalized shrinkage-thresholding operators for blind deconvolution</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[652,653]},"content":"<strong>针对 <em>Blind Deconvolution</em> 盲反卷积</strong>, <strong>推广</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">l</mi><mi mathvariant=\"bold-italic\">p</mi></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{l_p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9805em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1611em;\"><span style=\"top:-2.55em;margin-left:-0.0088em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>范数最小化的解到</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">p</mi><mo>&lt;</mo><mn mathvariant=\"bold\">0</mn></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{p &lt; 0}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">p</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel mathbf\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathbf\">0</span></span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[653,654]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">l</mi><mi mathvariant=\"bold-italic\">p</mi></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{l_p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9805em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.0088em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1611em;\"><span style=\"top:-2.55em;margin-left:-0.0088em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>范数最小化的解</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[654,655]},"content":"<strong>即,</strong> <strong><em>GST (Generalized Shrinkage-Thresholding)</em></strong>, <strong>广义阈值收缩算子</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[655,656]},"content":"<strong>动态地实现显著性边缘选择和时变正则化</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[656,657]},"content":"<strong>模糊核估计具有更好的鲁棒性</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[657,658]},"content":"<strong>2017, E, DE 解释 ResNet <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[658,659]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A proposal on machine learning via dynamical systems</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A proposal on machine learning via dynamical systems}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A proposal on machine learning via dynamical systems</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[659,660]},"content":"<strong>深度神经网络视为离散的动力系统</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[660,661]},"content":"<strong>Lu, <em>LM-architecture (Linear Multi-step architecture)</em></strong>, <strong>线性多步体系结构</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[661,662]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Beyond finite layer neural networks: bridging deep architectures and numerical differential equations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Beyond finite layer neural networks: bridging deep architectures and numerical differential equations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Beyond finite layer neural networks: bridging deep architectures and numerical differential equations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[662,663]},"content":"<strong>在任何类似ResNet的网络上使用</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[663,664]},"content":"<strong>具有更高的精度</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[664,665]},"content":"<strong>2018, Chen, <em>ODENet</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[665,666]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Neural ordinary differential equations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Neural ordinary differential equations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Neural ordinary differential equations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[666,667]},"content":"<strong>将神经网络对隐藏状态的导数进行参数化，不需要再分层传播梯度与更新参数，大幅降低了存储成本</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[667,668]},"content":"<strong>网络的输出通过计算常微分方程得到</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[668,669]},"content":"<strong>2019, Grathwohl, <em>FFJORD (Free-From Jacobian Of Reversible Dyanamics)</em></strong>, <strong>可逆动力学自由形式的雅可比矩阵</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[669,670]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>FFJORD: free-form continuous dynamics for scalable reversible generative models</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {FFJORD: free-form continuous dynamics for scalable reversible generative models}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">FFJORD: free-form continuous dynamics for scalable reversible generative models</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[670,671]},"content":"<strong>降低算法复杂性</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[671,672]},"content":"<strong>2009, Lin, 基于 PDE 的神经网络模型</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[672,673]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Designing partial differential equations for image processing by combining differential invariants</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Designing partial differential equations for image processing by combining differential invariants}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Designing partial differential equations for image processing by combining differential invariants</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[673,674]},"content":"<strong>2017, Haber, PDE 解释 ResNet 等</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[674,675]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Stable architectures for deep neural networks</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Stable architectures for deep neural networks}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Stable architectures for deep neural networks</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[675,676]},"content":"<strong>2020, Ruthotto, 基于拉格朗日乘子法的前向传播算法</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[676,677]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Deep neural networks motivated by partial differential equations</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Deep neural networks motivated by partial differential equations}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Deep neural networks motivated by partial differential equations</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[677,678]},"content":"<strong>PDE 约束优化中模型参数的正则化可以转化为神经网络输出的正则化</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[678,679]},"content":"<strong>模型在较少标签的情况下也具有较高的预测精度</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[679,680]},"content":"<strong>对目标任务更强的解释性, 但受限于优化方法本身缺陷, 如稳定性、计算复杂</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[680,681]},"content":"<img src=\"Conclusion.png\" alt=\"\" title=\"解释方法小结\">","children":[]}]},{"type":"list_item","depth":3,"payload":{"lines":[681,682]},"content":"<strong>应用</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[682,683]},"content":"<strong>2019, Guo, <em>LEMNA (Local Explanation Method using Nonlinear Approximation)</em></strong>, <strong>非线性近似的局部解释方法</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[683,684]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Explain the application of deep learning to network security with LEMNA</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Explain the application of deep learning to network security with LEMNA}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Explain the application of deep learning to network security with LEMNA</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[684,685]},"content":"<strong>引入 <em>Fused Lasso</em> 处理特征间的依赖关系, 融入到一个混合线性模型中拟合局部非线性的决策边界</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[685,686]},"content":"<strong><em>TEM (Tree-enhanced Embedding Method)</em></strong>, <strong>树增强嵌入方法</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[686,687]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>TEM: tree-enhanced embedding model for explainable recommendation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {TEM: tree-enhanced embedding model for explainable recommendation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">TEM: tree-enhanced embedding model for explainable recommendation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[687,688]},"content":"<strong>首先利用树模型学习显式的决策规则（交叉特征），然后使用嵌入模型合并交叉特征进行预测</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[688,689]},"content":"<strong>引入嵌入技术和注意力机制代替原本的全连接层</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[689,690]},"content":"<strong><em>MacridVAE (Macro-micro Disentangled Variational Auto-Encoder)</em></strong>, <strong>非纠缠表示的宏观-微观解离化VAE</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[690,691]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning disentangled representations for recommendation</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning disentangled representations for recommendation}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning disentangled representations for recommendation</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[691,692]},"content":"<strong>微解离通过 VAE 对信息进行理论解释，使每个维度可以独立反映一个低层次因素</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[692,693]},"content":"<strong>2021, Ye, 基于 <em>XGBoost</em> 和注意机制的可解释推荐模型</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[693,694]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>An interpretable mechanism for personalized recommendation based on cross feature</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {An interpretable mechanism for personalized recommendation based on cross feature}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">An interpretable mechanism for personalized recommendation based on cross feature</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[694,695]},"content":"<strong>XGBoost <mark>TODO</mark></strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[695,696]},"content":"<strong>模型预测的自解释</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[696,697]},"content":"<strong>2018, Biffi, 三维VAE</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[697,698]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Learning interpretable anatomical features through deep generative models: application to cardiac remodeling</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Learning interpretable anatomical features through deep generative models: application to cardiac remodeling}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Learning interpretable anatomical features through deep generative models: application to cardiac remodeling</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[698,699]},"content":"<strong>从 3D 分割中学习到的可解释的任务相关解剖学模式(Anatomic Pattern)</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[699,700]},"content":"<strong>2020, Schaumberg, 可解释的深度学习模型 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[700,701]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable multimodal deep learning for real-time pan-tissue pan-disease pathology search on social media</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable multimodal deep learning for real-time pan-tissue pan-disease pathology search on social media}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable multimodal deep learning for real-time pan-tissue pan-disease pathology search on social media</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[701,702]},"content":"<strong>2020, Wang, <em>scCapsNet (single-cell Capsule Networks)</em></strong>, <strong>使用胶囊网络的可解释深度学习架构</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[702,703]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>An interpretable deep-learning architecture of capsule networks for identifying cell-type gene expression programs from single-cell RNA-sequencing data</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {An interpretable deep-learning architecture of capsule networks for identifying cell-type gene expression programs from single-cell RNA-sequencing data}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">An interpretable deep-learning architecture of capsule networks for identifying cell-type gene expression programs from single-cell RNA-sequencing data</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[703,704]},"content":"<strong>识别竞争性单细胞类型，执行特征选择，进而识别编码不同类型亚细胞的基因组</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[704,705]},"content":"<strong>2021, Pintelas, 可解释的图像分类框架 <mark>TODO</mark></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[705,706]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A novel explainable image classification framework: case study on skin cancer and plant disease prediction</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A novel explainable image classification framework: case study on skin cancer and plant disease prediction}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A novel explainable image classification framework: case study on skin cancer and plant disease prediction</span></span></span></span></span>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[706,707]},"content":"<strong>皮肤癌的预测问题</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[707,708]},"content":"<strong>数据挖掘</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[708,709]},"content":"<strong><em>KDD</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[709,710]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>A study on different classification models for knowledge discovery</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {A study on different classification models for knowledge discovery}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">A study on different classification models for knowledge discovery</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[710,711]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Data mining and knowledge discovery in predictive toxicology</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Data mining and knowledge discovery in predictive toxicology}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Data mining and knowledge discovery in predictive toxicology</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[711,712]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Investigating and reflecting on the integration of automatic data analysis and visualization in knowledge discovery</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Investigating and reflecting on the integration of automatic data analysis and visualization in knowledge discovery}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Investigating and reflecting on the integration of automatic data analysis and visualization in knowledge discovery</span></span></span></span></span>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[712,713]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>From data mining to knowledge discovery in databases</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {From data mining to knowledge discovery in databases}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">From data mining to knowledge discovery in databases</span></span></span></span></span>","children":[]}]}]},{"type":"list_item","depth":4,"payload":{"lines":[713,714]},"content":"<strong>对抗攻击</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[714,715]},"content":"<strong>白盒对抗攻击</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[715,716]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Adversarial CAPTCHAs</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Adversarial CAPTCHAs}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Adversarial CAPTCHAs</span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[716,717]},"content":"<strong>已知目标模型的结构、参数信息，利用反向传播解释方法可探测模型的弱点</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[717,718]},"content":"<strong>Goodfellow, <em>FGSM</em></strong>, <strong>快速梯度符号攻击方法</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[718,719]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Explaining and harnessing adversarial examples</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Explaining and harnessing adversarial examples}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Explaining and harnessing adversarial examples</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[719,720]},"content":"<strong>输出相对于输入</strong>样本的<strong>梯度</strong>信息来<strong>探测</strong>模型的<strong>敏感性</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[720,721]},"content":"<strong>朝着敏感方向添加一个固定规模</strong>的<strong>噪音</strong>来<strong>生成对抗样本</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[721,722]},"content":"<strong>Papernot, <em>JSMA</em></strong>, <strong>雅可比显著图攻击</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[722,723]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>The limitations of deep learning in adversarial settings</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {The limitations of deep learning in adversarial settings}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">The limitations of deep learning in adversarial settings</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[723,724]},"content":"利用 <strong>Grad</strong> 解释方法<strong>生成显著图</strong>，<strong>选择最重要的特征进行攻击</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[724,725]},"content":"<strong>只需要扰动少量的特征</strong>就能达到<strong>很高的攻击成功率</strong>，<strong>隐蔽性更强</strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[725,726]},"content":"<strong>黑盒对抗攻击</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[726,727]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Adversarial examples versus cloud-based detectors: A black-box empirical study</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Adversarial examples versus cloud-based detectors: A black-box empirical study}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Adversarial examples versus cloud-based detectors: A black-box empirical study</span></span></span></span></span>","children":[{"type":"list_item","depth":7,"payload":{"lines":[727,728]},"content":"由于<strong>无法获取</strong>模型的<strong>结构信息</strong>，<strong>只能操纵</strong>模型的<strong>输入和输出</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[728,729]},"content":"<strong>Papernot, 针对黑盒机器学习模型的替代模型攻击方法</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[729,730]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Practical black-box attacks against machine learning</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Practical black-box attacks against machine learning}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Practical black-box attacks against machine learning</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[730,731]},"content":"<strong>模型蒸馏</strong>训练一个<strong>替代模型拟合</strong>目标黑盒模型的决策结果","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[731,732]},"content":"已有的攻击方法<strong>针对替代模型生成对抗样本</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[732,733]},"content":"利用<strong>生成的对抗样本</strong>对黑盒模型进行<strong>迁移攻击</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[733,734]},"content":"<strong>Li, <em>TextBugger</em></strong>, <strong>基于敏感性分析解释方法的文本对抗攻击方法</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[734,735]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>TextBugger: Generating adversarial text against real-world applications</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {TextBugger: Generating adversarial text against real-world applications}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">TextBugger: Generating adversarial text against real-world applications</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[735,736]},"content":"<strong>定位文本中的重要单词</strong>，利用符合人类感知的<strong>噪音逐个扰动重要的单词直到达到攻击目标</strong>","children":[]}]}]}]}]},{"type":"list_item","depth":3,"payload":{"lines":[736,737]},"content":"<strong>现存问题</strong>","children":[{"type":"list_item","depth":4,"payload":{"lines":[737,738]},"content":"<strong>自身脆弱性</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[738,739]},"content":"由于<strong>近似处理或基于优化手段</strong>，大多数<strong>解释方法</strong>只能提供<strong>近似的解释</strong>，因而<strong>解释结果</strong>与模型的<strong>真实行为</strong>之间存在一定的<strong>不一致性</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[739,740]},"content":"<strong>利用不一致性</strong>设计<strong>针对可解释</strong>系统的<strong>新型对抗样本攻击</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[740,741]},"content":"<strong>攻击目的</strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[741,742]},"content":"<strong>不改变</strong>模型的<strong>决策结果</strong>，<strong>使解释方法解释出错</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[742,743]},"content":"<strong>Ghorbani, 模型解释脆弱性</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[743,744]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretation of neural networks is fragile</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretation of neural networks is fragile}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretation of neural networks is fragile</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[744,745]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mtable rowspacing=\"0.25em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi mathvariant=\"bold-italic\">δ</mi></munder><mi mathvariant=\"bold-italic\">D</mi><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold-italic\">I</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">t</mi></msub><mo separator=\"true\">;</mo><mi mathvariant=\"bold-italic\">N</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">I</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">t</mi></msub><mo mathvariant=\"bold-italic\">+</mo><mi mathvariant=\"bold-italic\">δ</mi><mo separator=\"true\">;</mo><mi mathvariant=\"bold-italic\">N</mi><mo stretchy=\"false\">)</mo><mo fence=\"true\">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">.</mi></mrow><mo>∥</mo><mi mathvariant=\"bold-italic\">δ</mi><msub><mo>∥</mo><mi mathvariant=\"bold\">∞</mi></msub><mo>⩽</mo><mi mathvariant=\"bold-italic\">ε</mi><mo separator=\"true\">,</mo><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">t</mi></msub><mo mathvariant=\"bold-italic\">+</mo><mi mathvariant=\"bold-italic\">δ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr></mtable></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{\\begin{aligned}\\arg\\max_{\\delta}D\\left(I(x_{t};N),I(x_{t}+\\delta;N)\\right)\\\\\\mathrm{s.t.}\\parallel\\delta\\parallel_{\\infty}\\leqslant\\varepsilon,f(x_{t}+\\delta)=f(x_{t}) \\end{aligned}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:3.3921em;vertical-align:-1.4461em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.9461em;\"><span style=\"top:-4.1061em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">ar<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4306em;\"><span style=\"top:-2.3479em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03785em;\">δ</span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">max</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7521em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03785em;\">δ</span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span><span style=\"top:-2.2139em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathrm\">s.t.</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∥</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03785em;\">δ</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\"><span class=\"mrel\">∥</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∞</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mrel amsrm\">⩽</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\">ε</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03785em;\">δ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.4461em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":9,"payload":{"lines":[745,746]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">I</mi><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><msub><mrow></mrow><mi mathvariant=\"bold-italic\">t</mi></msub></msub><mo separator=\"true\">;</mo><mi mathvariant=\"bold-italic\">N</mi><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{I\\left(x_{_{t}};N\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0001em;vertical-align:-0.2501em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.07778em;\">I</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.0674em;\"><span style=\"top:-2.35em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3105em;\"><span style=\"top:-2.357em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord boldsymbol mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2501em;\"><span></span></span></span></span></span></span><span class=\"mpunct mathbf\">;</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord boldsymbol\" style=\"margin-right:0.11424em;\">N</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":10,"payload":{"lines":[746,747]},"content":"<strong>解释系统对神经网络</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">N</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{N}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11424em;\">N</span></span></span></span></span></span> <strong>针对样本</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">t</mi></msub></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{x_t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5944em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2944em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></span> <strong>决策结果</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">f</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{f(x_t)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11042em;\">f</span><span class=\"mopen mathbf\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2944em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose mathbf\">)</span></span></span></span></span></span> <strong>的解释</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[747,748]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">δ</mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{\\delta}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.03819em;\">δ</span></span></span></span></span></span>","children":[{"type":"list_item","depth":10,"payload":{"lines":[748,749]},"content":"<strong>样本</strong>中<strong>所需</strong>添加的<strong>扰动</strong>","children":[]}]},{"type":"list_item","depth":9,"payload":{"lines":[749,750]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">D</mi><mrow><mo fence=\"true\">(</mo><mo mathvariant=\"bold-italic\">∙</mo><mo fence=\"true\">)</mo></mrow></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\boldsymbol{D\\left(\\bullet\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.03194em;\">D</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathbf\">∙</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span></span>","children":[{"type":"list_item","depth":10,"payload":{"lines":[750,751]},"content":"<strong>度量扰动前后解释结果的变化</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[751,752]},"content":"<strong><em>Grad</em></strong>, <strong><em>Integrated</em></strong>, <strong><em>DeepLIFT</em></strong> <strong>等反向传播解释方法</strong>，均<strong>易受到对抗样本攻击</strong>，<strong>只能提供脆弱的模型解释</strong>","children":[]}]}]},{"type":"list_item","depth":6,"payload":{"lines":[752,753]},"content":"<strong>不改变解释方法的解释结果</strong>，<strong>使模型决策出错</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[753,754]},"content":"<strong>Zhang, <em>Acid</em> 攻击</strong>","children":[{"type":"list_item","depth":8,"payload":{"lines":[754,755]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Interpretable deep learning under fire</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Interpretable deep learning under fire}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Interpretable deep learning under fire</span></span></span></span></span>","children":[]},{"type":"list_item","depth":8,"payload":{"lines":[755,756]},"content":"<strong>生成欺骗分类器及其解释方法</strong>的对抗样本实际上<strong>并不比生成仅能欺骗分类器的对抗样本更困难</strong>","children":[{"type":"list_item","depth":9,"payload":{"lines":[756,757]},"content":"<strong>同样是脆弱的</strong>","children":[{"type":"list_item","depth":10,"payload":{"lines":[757,758]},"content":"<strong>表示导向(激活最大化、特征反演等)</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[758,759]},"content":"<strong>模型导向(如基于掩码模型的显著性检测等)</strong>","children":[]},{"type":"list_item","depth":10,"payload":{"lines":[759,760]},"content":"<strong>扰动导向(如敏感性分析等)</strong>","children":[]}]}]},{"type":"list_item","depth":8,"payload":{"lines":[760,761]},"content":"并且<strong>使基于对比攻击前后解释结果的防御方法失效</strong>","children":[]}]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[761,762]},"content":"<strong>消除解释方法与决策系统之间的不一致性</strong>则是<strong>提高</strong>解释方法<strong>鲁棒性</strong>进而消除其外在安全隐患的<strong>重要途径</strong>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[762,763]},"content":"<strong><mark>精确解释方法设计</mark></strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[763,764]},"content":"<strong>挑战: 消除模型准确性与可解释性之间的制约</strong>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[764,765]},"content":"<strong><em>ante-hoc</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[765,766]},"content":"<strong>可能路径</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[766,767]},"content":"<strong>结合机器学习与因果模型</strong>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[767,768]},"content":"<strong>结合机器学习与常识推理和类比计算等技术，形成可解释的、能自动推理的学习系统</strong>","children":[]}]}]},{"type":"list_item","depth":5,"payload":{"lines":[768,769]},"content":"<strong><em>post-hoc</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[769,770]},"content":"<strong>可能路径</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[770,771]},"content":"<strong><mark>设计数学上与待解释模型等价的解释方法或解释模型</mark></strong>","children":[]}]}]}]},{"type":"list_item","depth":4,"payload":{"lines":[771,772]},"content":"<strong>解释方法评估</strong>","children":[{"type":"list_item","depth":5,"payload":{"lines":[772,773]},"content":"<strong><em>ante-hoc</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[773,774]},"content":"<strong>挑战: 如何量化模型的内在解释能力</strong>","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[774,775]},"content":"<strong><em>post-hoc</em></strong>","children":[{"type":"list_item","depth":6,"payload":{"lines":[775,776]},"content":"<strong>挑战: 如何量化解释结果的保真度和一致性</strong>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[776,777]},"content":"<strong>Guo, <em>RMSE</em></strong>, <strong>解释方法</strong>给出的<strong>预测结果</strong>与<strong>待解释</strong>模型<strong>预测结果</strong>之间的<strong>均方根误差</strong>评估解释方法的<strong>保真度</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[777,778]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Lemna: Explaining deep learning based security applications</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Lemna: Explaining deep learning based security applications}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Lemna: Explaining deep learning based security applications</span></span></span></span></span>","children":[]},{"type":"list_item","depth":7,"payload":{"lines":[778,779]},"content":"<strong>无法用于</strong>评估激活最大化、敏感性分析、反向传播以及特征反演等<strong>不提供预测结果的解释方法</strong>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[779,780]},"content":"<strong>Chu, 输入样本及其邻近样本</strong>的<strong>解释结果的余弦相似性</strong>来评估解释方法，<strong>无法</strong>用于<strong>评估解释结果</strong>的<strong>保真度</strong>","children":[{"type":"list_item","depth":7,"payload":{"lines":[780,781]},"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mstyle mathcolor=\"green\"><mtext>Exact and consistent interpretation for piecewise linear neural networks: A closed form solution</mtext></mstyle></mrow><annotation encoding=\"application/x-tex\">\\color{green} \\text {Exact and consistent interpretation for piecewise linear neural networks: A closed form solution}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\" style=\"color:green;\"><span class=\"mord\" style=\"color:green;\">Exact and consistent interpretation for piecewise linear neural networks: A closed form solution</span></span></span></span></span>","children":[]}]},{"type":"list_item","depth":6,"payload":{"lines":[781,782]},"content":"<strong>仍然缺乏</strong>用于评估针对<strong>同一模型</strong>的<strong>不同解释方法的定量评估指标</strong>","children":[]}]}]}]}]}]}],"payload":{}},{})</script>
</body>
</html>
